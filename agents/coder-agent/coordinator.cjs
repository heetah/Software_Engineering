/**
 * Coordinator - å”èª¿éª¨æ¶ç”Ÿæˆå’Œç´°ç¯€å¡«å……çš„æ ¸å¿ƒé‚è¼¯
 * 
 * æµç¨‹:
 * 1. Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆå–®æ¬¡æˆ–åˆ†æ‰¹ API å‘¼å«ï¼‰
 * 2. Phase 2: åºåˆ—åŒ–ç”Ÿæˆæ¯å€‹æª”æ¡ˆçš„ç´°ç¯€ï¼ˆä¸€æ¬¡ä¸€å€‹ agentï¼Œç¢ºä¿æ­£ç¢ºæ€§ï¼‰
 * 3. Phase 3: çµ„è£å’Œé©—è­‰æœ€çµ‚çµæœ
 */

const logger = require('../shared/logger.cjs');
const path = require('path');
const DependencyAnalyzer = require('./dependency-analyzer');
const ConfigGenerator = require('./config-generator');
// const ContractsAgent = require('./contracts-agent'); // DISABLED - Architect provides complete contracts
const ContractsExtractor = require('./contracts-extractor');

// è¼‰å…¥ Worker Generatorsï¼ˆæœ¬åœ°èª¿ç”¨ï¼Œä¸éœ€è¦ HTTPï¼‰
const MarkupGenerator = require('../worker-agents/markup-agent/generator');
const ScriptGenerator = require('../worker-agents/script-agent/generator');
const StyleGenerator = require('../worker-agents/style-agent/generator');
const PythonGenerator = require('../worker-agents/python-agent/generator');
const SystemGenerator = require('../worker-agents/system-agent/generator');

class Coordinator {
  constructor(config = {}) {
    // ä¾è³´åˆ†æå™¨
    this.dependencyAnalyzer = new DependencyAnalyzer();

    // å‹•æ…‹ Contracts æå–å™¨
    this.contractsExtractor = new ContractsExtractor();

    // å‹•æ…‹ Contracts æå–å™¨
    this.contractsExtractor = new ContractsExtractor();

    // é…ç½®åƒæ•¸ï¼ˆå…ˆè¨­å®šï¼Œå†å‚³çµ¦ workersï¼‰
    this.MAX_FILES_PER_SKELETON_BATCH = config.maxSkeletonBatch || 30; // æ“´å¤§æ‰¹æ¬¡ä»¥æ”¯æŒå¤§å‹å°ˆæ¡ˆ
    this.DETAIL_GENERATION_DELAY = config.detailDelay || 1500; // æ¯«ç§’

    // API é…ç½®å„ªå…ˆé †åºï¼š1. config åƒæ•¸ (Frontend Keys) 2. CLOUD_API 3. OPENAI_API
    const provider = (config.llmProvider || "auto").toLowerCase();

    let apiKey = config.cloudApiKey;
    let endpoint = config.cloudApiEndpoint;

    // æ ¹æ“š Provider é¸æ“‡ Key
    if (provider === 'gemini') {
      apiKey = config.geminiApiKey || process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY;
      endpoint = "https://generativelanguage.googleapis.com/v1beta";
    } else if (provider === 'openai') {
      apiKey = config.openaiApiKey || process.env.OPENAI_API_KEY;
      endpoint = "https://api.openai.com/v1";
    } else if (provider === 'auto') {
      // Autoå„ªå…ˆé †åºï¼šå‚³å…¥çš„ OpenAI -> å‚³å…¥çš„ Gemini -> ç’°å¢ƒè®Šæ•¸ OpenAI -> ç’°å¢ƒè®Šæ•¸ Gemini
      if (config.openaiApiKey) {
        apiKey = config.openaiApiKey;
        endpoint = "https://api.openai.com/v1";
      } else if (config.geminiApiKey) {
        apiKey = config.geminiApiKey;
        endpoint = "https://generativelanguage.googleapis.com/v1beta";
      } else if (process.env.OPENAI_API_KEY) {
        apiKey = process.env.OPENAI_API_KEY;
        endpoint = "https://api.openai.com/v1";
      } else if (process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY) {
        apiKey = process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY;
        endpoint = "https://generativelanguage.googleapis.com/v1beta";
      }
    }

    this.CLOUD_API_ENDPOINT = endpoint;
    this.CLOUD_API_KEY = apiKey;

    // é è¨­ä½¿ç”¨çœŸå¯¦ APIï¼ˆä¸ä½¿ç”¨ mockï¼‰
    this.USE_MOCK_API = config.useMockApi === true;

    // å»ºç«‹ worker configï¼Œç¢ºä¿å‚³é API é…ç½®
    const workerConfig = {
      ...config,
      cloudApiEndpoint: this.CLOUD_API_ENDPOINT,
      cloudApiKey: this.CLOUD_API_KEY,
      useMockApi: this.USE_MOCK_API
    };

    // Worker generators é…ç½®ï¼ˆæœ¬åœ°èª¿ç”¨ï¼‰
    this.workers = {
      'markup': {
        generator: new MarkupGenerator(workerConfig),
        exts: ['.html', '.xml', '.md', '.htm', '.txt', '.gitignore', '.env', '.ps1', '.sh', '.bat', '.json']
      },
      'script': {
        generator: new ScriptGenerator(workerConfig),
        exts: ['.js', '.ts', '.jsx', '.tsx', '.mjs', '.cjs']
      },
      'style': {
        generator: new StyleGenerator(workerConfig),
        exts: ['.css', '.scss', '.sass', '.less']
      },
      'python': {
        generator: new PythonGenerator(workerConfig),
        exts: ['.py']
      },
      'system': {
        generator: new SystemGenerator(workerConfig),
        exts: ['.c', '.cpp', '.h', '.hpp', '.go', '.rs', '.java', '.cs']
      }
    };

    logger.info('Coordinator initialized (local generators)', null, {
      use_mock_api: this.USE_MOCK_API,
      has_api_config: !!(this.CLOUD_API_ENDPOINT && this.CLOUD_API_KEY),
      worker_generators: Object.keys(this.workers).length,
      max_skeleton_batch: this.MAX_FILES_PER_SKELETON_BATCH
    });
  }

  /**
   * ä¸»å…¥å£ï¼šå¾ architect payload ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆ
   */
  async generateFromArchitectPayload(payload, requestId = null) {
    logger.info('Coordinator starting - preprocessing payload', requestId);

    try {
      // Phase -1: Contracts Agent é è™•ç† payload (DISABLED - Architect Agent already provides complete contracts)
      // logger.info('Phase -1: Running Contracts Agent preprocessing', requestId);
      // const contractsAgent = new ContractsAgent();
      // const enhancedPayload = await contractsAgent.processPayload(payload);

      // è·³é ContractsAgentï¼Œç›´æ¥ä½¿ç”¨ Architect çš„è¼¸å‡º
      const enhancedPayload = payload;
      logger.info('Phase -1: Skipped (using Architect contracts directly)', requestId);

      // ä½¿ç”¨å¢å¼·å¾Œçš„ payload ç¹¼çºŒ
      const coderInstructions = enhancedPayload.output.coder_instructions;
      const files = coderInstructions.files;
      const contracts = coderInstructions.contracts || null;
      const projectConfig = coderInstructions.projectConfig || null;

      logger.info('Starting generation with enhanced payload', requestId, {
        totalFiles: files.length,
        hasContracts: !!contracts,
        hasProjectConfig: !!projectConfig,
        useMockApi: this.USE_MOCK_API
      });

      // Phase 0: è‡ªå‹•ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
      logger.info('Phase 0: Generating config files', requestId);
      const configFiles = ConfigGenerator.generateAll(coderInstructions);
      if (configFiles.length > 0) {
        logger.info('Config files generated', requestId, {
          files: configFiles.map(f => f.path)
        });
        // å°‡é…ç½®æ–‡ä»¶åŠ å…¥åˆ°æ–‡ä»¶åˆ—è¡¨ä¸­
        files.unshift(...configFiles);
      }

      // Phase 1: ç”Ÿæˆéª¨æ¶ï¼ˆå‚³éå®Œæ•´çš„ coder_instructions åŒ…å« contractsï¼‰
      logger.info('Phase 1: Generating skeletons', requestId);
      const skeletons = await this.generateAllSkeletons(coderInstructions, requestId);

      // Phase 2: åºåˆ—åŒ–ç”Ÿæˆç´°ç¯€ï¼ˆå‚³é contracts å’Œ projectConfigï¼‰
      logger.info('Phase 2: Generating details sequentially', requestId);
      const detailedFiles = await this.generateDetailsSequentially(files, skeletons, contracts, projectConfig, requestId);

      // Phase 3: çµ„è£ï¼ˆå‚³é payload ä»¥ä¾¿ç”Ÿæˆ setup æª”æ¡ˆï¼‰
      logger.info('Phase 3: Assembling results', requestId);
      const result = await this.assemble(detailedFiles, skeletons, requestId, enhancedPayload.output);

      logger.info('Coordinator completed', requestId, {
        filesGenerated: result.files.length,
        configFiles: configFiles.length,
        successful: detailedFiles.filter(f => !f.error).length,
        failed: detailedFiles.filter(f => f.error).length
      });

      return result;

    } catch (error) {
      logger.error('Coordinator failed', requestId, {
        error: error.message,
        stack: error.stack
      });
      throw error;
    }
  }

  /**
   * Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆè‡ªå‹•åˆ†æ‰¹ï¼‰
   */
  /**
   * Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆè‡ªå‹•åˆ†æ‰¹ï¼‰
   * @param {Object} coderInstructions - åŒ…å« files, requirements, contracts
   */
  async generateAllSkeletons(coderInstructions, requestId) {
    const files = Array.isArray(coderInstructions) ? coderInstructions : coderInstructions.files;
    logger.info('Generating skeletons with auto-batching', requestId, {
      totalFiles: files.length
    });

    // ç›´æ¥å‘¼å« generateSkeletonsBatchï¼Œå®ƒæœƒè‡ªå‹•æ±ºå®šæ˜¯å¦åˆ†æ‰¹
    // å‚³éå®Œæ•´çš„ coderInstructionsï¼ˆåŒ…å« contractsï¼‰
    return await this.generateSkeletonsBatch(coderInstructions, requestId);
  }

  /**
   * å–®æ¬¡æˆ–åˆ†æ‰¹ç”Ÿæˆéª¨æ¶ï¼ˆè‡ªå‹•æª¢æ¸¬æ˜¯å¦éœ€è¦åˆ†æ‰¹ï¼‰
   * @param {Object|Array} coderInstructions - å¯ä»¥æ˜¯ {files, contracts} æˆ–ç´” files[]
   */
  async generateSkeletonsBatch(coderInstructions, requestId) {
    // æ¯æ‰¹æœ€å¤šå¤šå°‘æª”æ¡ˆï¼ˆå¯ç”±å»ºæ§‹å­ / ç’°å¢ƒè®Šæ•¸èª¿æ•´ï¼‰
    const MAX_FILES_PER_BATCH = this.MAX_FILES_PER_SKELETON_BATCH || 5;

    // ç›¸å®¹èˆŠæ ¼å¼ï¼šå¦‚æœå‚³å…¥çš„æ˜¯é™£åˆ—ï¼Œè½‰æ›æˆç‰©ä»¶
    const payload = Array.isArray(coderInstructions)
      ? { files: coderInstructions }
      : coderInstructions;

    const files = payload.files;

    // å¦‚æœæª”æ¡ˆæ•¸ <= 5ï¼Œå–®æ¬¡ç”Ÿæˆ
    if (files.length <= MAX_FILES_PER_BATCH) {
      logger.info('Calling cloud API for skeleton generation (single batch)', requestId, {
        fileCount: files.length
      });

      return await this.generateSkeletonsSingleBatch(payload, requestId);
    }

    // å¦å‰‡åˆ†æ‰¹ç”Ÿæˆ
    logger.info('Files exceed batch limit, splitting into multiple batches', requestId, {
      totalFiles: files.length,
      batchSize: MAX_FILES_PER_BATCH
    });

    const skeletonMap = {};

    // æŒ‰èªè¨€åˆ†çµ„ï¼ˆåŒé¡å‹æª”æ¡ˆæ”¾ä¸€èµ·ï¼‰
    const batches = [];
    const byLanguage = {};

    files.forEach(f => {
      const lang = f.language || 'unknown';
      if (!byLanguage[lang]) byLanguage[lang] = [];
      byLanguage[lang].push(f);
    });

    // å°‡æ¯å€‹èªè¨€çš„æª”æ¡ˆåˆ†æˆå°æ‰¹æ¬¡
    Object.values(byLanguage).forEach(langFiles => {
      for (let i = 0; i < langFiles.length; i += MAX_FILES_PER_BATCH) {
        batches.push(langFiles.slice(i, i + MAX_FILES_PER_BATCH));
      }
    });

    logger.info('Created batches for skeleton generation', requestId, {
      totalBatches: batches.length,
      batchSizes: batches.map(b => b.length)
    });

    // é€æ‰¹ç”Ÿæˆ
    for (let i = 0; i < batches.length; i++) {
      logger.info(`Processing skeleton batch ${i + 1}/${batches.length}`, requestId, {
        filesInBatch: batches[i].length,
        files: batches[i].map(f => f.path)
      });

      // æ¯å€‹ batch ä¹Ÿå‚³é contractsï¼ˆå¦‚æœæœ‰ï¼‰
      const batchPayload = {
        files: batches[i],
        contracts: payload.contracts || null,
        requirements: payload.requirements || null
      };

      const batchSkeletons = await this.generateSkeletonsSingleBatch(batchPayload, requestId);
      Object.assign(skeletonMap, batchSkeletons);

      // æ‰¹æ¬¡é–“å»¶é²ï¼ˆé¿å… API rate limitï¼‰ï¼Œå¿«é€Ÿæ¨¡å¼å¯ç‚º 0
      if (i < batches.length - 1 && this.SKELETON_BATCH_DELAY > 0) {
        logger.info(
          `Waiting ${this.SKELETON_BATCH_DELAY}ms before next batch...`,
          requestId
        );
        await this.sleep(this.SKELETON_BATCH_DELAY);
      }
    }

    logger.info('All skeleton batches completed', requestId, {
      totalSkeletons: Object.keys(skeletonMap).length
    });

    return skeletonMap;
  }

  /**
   * å–®æ¬¡ API å‘¼å«ç”Ÿæˆéª¨æ¶ï¼ˆä¸åˆ†æ‰¹ï¼‰
   * @param {Object} payload - åŒ…å« files, contracts, requirements
   */
  async generateSkeletonsSingleBatch(payload, requestId) {
    // ç›¸å®¹èˆŠæ ¼å¼ï¼šå¦‚æœå‚³å…¥çš„æ˜¯é™£åˆ—ï¼Œè½‰æ›æˆç‰©ä»¶
    if (Array.isArray(payload)) {
      payload = { files: payload };
    }

    const files = payload.files;

    logger.info('Calling cloud API for skeleton generation', requestId, {
      fileCount: files.length
    });

    // æº–å‚™ API payload
    const apiPayload = {
      task: 'generate_skeletons',
      instructions: 'Generate code skeletons for all specified files. Include only structure, imports, and signatures. NO implementation details.',
      files: payload.files.map(f => ({
        path: f.path,
        language: f.language,
        description: f.description || '',
        requirements: Array.isArray(f.requirements) ? f.requirements : []
      })),
      constraints: {
        output_format: 'skeleton_only',
        include: ['imports', 'exports', 'class_signatures', 'function_signatures', 'type_definitions', 'docstrings'],
        exclude: ['implementation', 'detailed_logic', 'inline_comments', 'test_code']
      }
    };

    // å‘¼å«é›²ç«¯ API
    const response = await this.callCloudAPI(apiPayload, requestId);

    // è§£æå›å‚³çš„éª¨æ¶
    const skeletonMap = {};

    if (response.skeletons && Array.isArray(response.skeletons)) {
      logger.info('Processing skeleton response', requestId, {
        receivedCount: response.skeletons.length,
        expectedCount: files.length
      });

      response.skeletons.forEach(skeleton => {
        if (skeleton.path && skeleton.content) {
          skeletonMap[skeleton.path] = skeleton.content;
          logger.debug(`âœ“ Skeleton for ${skeleton.path}`, requestId, {
            contentLength: skeleton.content.length
          });
        } else {
          logger.warn(`âš  Invalid skeleton entry`, requestId, { skeleton });
        }
      });

      // æª¢æŸ¥æ˜¯å¦æœ‰æª”æ¡ˆç¼ºå°‘éª¨æ¶
      const missing = files.filter(f => !skeletonMap[f.path]);
      if (missing.length > 0) {
        logger.warn('Some files missing skeletons', requestId, {
          missingFiles: missing.map(f => f.path),
          receivedSkeletons: Object.keys(skeletonMap)
        });
      }
    } else {
      logger.warn('Invalid skeleton response format', requestId, { response });
      throw new Error('Cloud API returned invalid skeleton format');
    }

    logger.info('Skeletons generated successfully', requestId, {
      count: Object.keys(skeletonMap).length,
      files: Object.keys(skeletonMap)
    });

    return skeletonMap;
  }

  /**
   * Phase 2: æ ¹æ“šä¾è³´é—œä¿‚ç”Ÿæˆç´°ç¯€ï¼ˆä½µç™¼æˆ–åºåˆ—ï¼‰
   */
  /**
   * Phase 2: åºåˆ—åŒ–ç”Ÿæˆç´°ç¯€ï¼ˆä¾è³´åˆ†å±¤ï¼Œå±¤å…§ä½µç™¼ï¼‰
   * @param {Array} files - æª”æ¡ˆåˆ—è¡¨
   * @param {Object} skeletons - éª¨æ¶å°æ‡‰è¡¨
   * @param {Object} contracts - å¯é¸çš„è·¨æª”æ¡ˆ contracts
   * @param {Object} projectConfig - é …ç›®é…ç½®ï¼ˆç«¯å£ã€APIç­‰ï¼‰
   */
  async generateDetailsSequentially(files, skeletons, contracts, projectConfig, requestId) {
    // åˆ†ææª”æ¡ˆä¾è³´é—œä¿‚
    const { order, groups, depGraph } = this.dependencyAnalyzer.analyze(files, skeletons, requestId);

    // è¦–è¦ºåŒ–ä¾è³´é—œä¿‚ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
    this.dependencyAnalyzer.visualizeDependencies(depGraph, groups, requestId);

    // ğŸ”„ å‹•æ…‹ Contractsï¼šæœƒéš¨è‘—æ¯å±¤ç”Ÿæˆå®Œç•¢è€Œæ›´æ–°
    let dynamicContracts = contracts ? { ...contracts } : { dom: [], api: [], storage: [] };

    logger.info('Starting layered detail generation', requestId, {
      totalFiles: files.length,
      layers: groups.length,
      strategy: groups.length === 1 ? 'all-concurrent' : 'layered-concurrent',
      hasContracts: !!contracts,
      dynamicContractsEnabled: true
    });

    const results = [];
    const fileMap = {};
    files.forEach(f => { fileMap[f.path] = f; });

    // é€å±¤ç”Ÿæˆï¼ˆæ¯å±¤å…§éƒ¨ä½µç™¼ï¼Œå±¤èˆ‡å±¤ä¹‹é–“åºåˆ—ï¼‰
    for (let layerIdx = 0; layerIdx < groups.length; layerIdx++) {
      const layer = groups[layerIdx];
      const isLastLayer = layerIdx === groups.length - 1;

      logger.info(`Processing Layer ${layerIdx + 1}/${groups.length}`, requestId, {
        filesInLayer: layer.length,
        files: layer.map(p => path.basename(p))
      });

      // å±¤å…§ä½µç™¼ç”Ÿæˆ
      const layerPromises = layer.map(async (filePath) => {
        const file = fileMap[filePath];

        // ğŸ”’ è·³éè‡ªå‹•ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ï¼ˆç›´æ¥ä½¿ç”¨ ConfigGenerator çš„æ¨¡æ¿ï¼‰
        if (file.isAutoGenerated && file.content) {
          logger.info(`â­ Skipping AI generation for ${file.path} (using template)`, requestId);
          return {
            path: file.path,
            content: file.content,
            language: file.type,
            metadata: { skipped: true, reason: 'auto-generated config file' }
          };
        }

        const agent = this.selectAgent(file.path);
        const agentName = this.getAgentName(agent);

        try {
          // å»ºç«‹ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å·²å®Œæˆçš„ä¾è³´æª”æ¡ˆ + contractsï¼‰
          const deps = depGraph[filePath] || [];
          const completedDeps = results
            .filter(r => !r.error && deps.includes(r.path))
            .map(r => ({ path: r.path, content: r.content, language: r.language }));

          const fileSkeleton = skeletons[file.path];
          if (!fileSkeleton) {
            logger.warn(`âš  No skeleton found for ${file.path}`, requestId);
          }

          // Speed Optimization: Determine Model Tier (Adaptive Selection)
          // Simple files use 'fast' tier (Quantized/Mobile models)
          const ext = path.extname(file.path).toLowerCase();
          const fastExtensions = ['.css', '.scss', '.sass', '.less', '.html', '.htm', '.json', '.xml', '.md', '.txt', '.env', '.gitignore'];
          const isSimpleFile = fastExtensions.includes(ext);
          const modelTier = isSimpleFile ? 'fast' : 'strong';

          if (isSimpleFile) {
            logger.info(`âš¡ assigning FAST tier for ${path.basename(file.path)}`, requestId);
          }

          const context = {
            skeleton: fileSkeleton,
            allSkeletons: skeletons,
            completedFiles: results
              .filter(r => !r.error)
              .map(r => ({ path: r.path, content: r.content, language: r.language })),
            dependencies: completedDeps,
            allFiles: files, // å‚³éæ‰€æœ‰æª”æ¡ˆè³‡è¨Šï¼ˆç”¨æ–¼é çŸ¥å°‡ä¾†çš„æª”æ¡ˆï¼‰
            contracts: dynamicContracts, // â† ğŸ”„ ä½¿ç”¨å‹•æ…‹æ›´æ–°çš„ contracts
            projectConfig: projectConfig || null, // â† æ–°å¢ï¼šå‚³éé …ç›®é…ç½®çµ¦ Worker Agents
            modelTier: modelTier, // â† Add modelTier to context
            fileSpec: {
              path: file.path,
              language: file.language,
              description: file.description || '',
              requirements: file.requirements || [],
              template: file.template || null // â† ğŸ”¥ CRITICAL: å‚³é template çµ¦ Worker Agents
            }
          };

          // å‘¼å« worker agent
          const result = await this.generateFileDetail(agent, file, context, requestId);

          if (!result.content || result.content.trim() === '') {
            logger.warn(`âš  Worker agent returned empty content for ${file.path}`, requestId);
          }

          logger.info(`âœ… Generated ${path.basename(file.path)}`, requestId, {
            layer: layerIdx + 1,
            agent: agentName,
            tokens: result.metadata?.tokens_used,
            size: result.content?.length || 0,
            hasContent: !!(result.content && result.content.trim())
          });

          return {
            path: file.path,
            content: result.content,
            language: file.language,
            metadata: result.metadata || {},
            layer: layerIdx + 1
          };

        } catch (error) {
          logger.error(`âŒ Failed to generate ${path.basename(file.path)}`, requestId, {
            layer: layerIdx + 1,
            error: error.message
          });

          // å¤±æ•—æ™‚ä½¿ç”¨éª¨æ¶ä½œç‚º fallback
          return {
            path: file.path,
            content: skeletons[file.path] || `// Error generating ${file.path}: ${error.message}`,
            language: file.language,
            error: error.message,
            layer: layerIdx + 1
          };
        }
      });

      // ç­‰å¾…ç•¶å‰å±¤çš„æ‰€æœ‰æª”æ¡ˆç”Ÿæˆå®Œæˆ
      const layerResults = await Promise.all(layerPromises);
      results.push(...layerResults);

      // ğŸ”„ å‹•æ…‹æ›´æ–° Contractsï¼šå¾æœ¬å±¤ç”Ÿæˆçš„æª”æ¡ˆä¸­æå–å¯¦éš›çš„ DOM IDs, IPC channels ç­‰
      if (!isLastLayer) {
        const successfulLayerResults = layerResults.filter(r => !r.error && r.content);
        if (successfulLayerResults.length > 0) {
          const extracted = this.contractsExtractor.extractFromFiles(successfulLayerResults, requestId);
          dynamicContracts = this.contractsExtractor.mergeContracts(dynamicContracts, extracted, requestId);

          logger.info(`Dynamic contracts updated after Layer ${layerIdx + 1}`, requestId, {
            domElements: dynamicContracts.dom.length,
            apiEndpoints: dynamicContracts.api.length,
            storageKeys: dynamicContracts.storage.length,
            newlyExtracted: {
              dom: extracted.dom.length,
              api: extracted.api.length,
              storage: extracted.storage.length
            }
          });
        }
      }

      // å±¤èˆ‡å±¤ä¹‹é–“å»¶é²ï¼ˆæœ€å¾Œä¸€å±¤ä¸éœ€è¦å»¶é²ï¼‰
      if (!isLastLayer) {
        logger.info(`Layer ${layerIdx + 1} completed, waiting before next layer...`, requestId);
        await this.sleep(this.DETAIL_GENERATION_DELAY);
      }
    }

    const successful = results.filter(r => !r.error).length;
    const failed = results.filter(r => r.error).length;

    logger.info('Layered generation completed', requestId, {
      totalLayers: groups.length,
      successful,
      failed,
      successRate: `${(successful / files.length * 100).toFixed(1)}%`
    });

    return results;
  }

  /**
   * Phase 3: çµ„è£æœ€çµ‚çµæœ
   */
  async assemble(detailedFiles, skeletons, requestId, payload = null) {
    const successful = detailedFiles.filter(f => !f.error);
    const failed = detailedFiles.filter(f => f.error);

    const notes = [
      `Generated ${detailedFiles.length} files`,
      `âœ… Successful: ${successful.length}`,
      failed.length > 0 ? `âŒ Failed: ${failed.length}` : null,
      'All files processed via Coordinator'
    ].filter(Boolean);

    // æ·»åŠ å¤±æ•—çš„æª”æ¡ˆè©³æƒ…
    if (failed.length > 0) {
      notes.push('Failed files:');
      failed.forEach(f => {
        notes.push(`  - ${f.path}: ${f.error}`);
      });
    }

    // æ”¶é›†æ‰€æœ‰æª”æ¡ˆï¼ˆåŒ…æ‹¬ç”Ÿæˆçš„å’Œ setup æª”æ¡ˆï¼‰
    let allFiles = detailedFiles.map(f => ({
      path: f.path,
      template: f.content,
      language: f.language
    }));

    // å¦‚æœ payload æœ‰ setup æ¬„ä½ï¼Œè‡ªå‹•ç”Ÿæˆ setup æª”æ¡ˆ
    if (payload && payload.coder_instructions && payload.coder_instructions.setup) {
      const setupFiles = this.generateSetupFiles(payload.coder_instructions.setup);
      allFiles = allFiles.concat(setupFiles);
      notes.push(`ğŸ“¦ Generated ${setupFiles.length} setup files (package.json, README.md, etc.)`);
    }

    return {
      request_id: `coder-${Date.now()}`,
      received_at: new Date().toISOString(),
      suggested_action: 'generate_files',
      notes: notes,
      files: allFiles,
      metadata: {
        total_files: allFiles.length,
        successful_files: successful.length,
        failed_files: failed.length,
        coordinator_version: '1.0.0',
        generation_method: 'skeleton_then_details'
      }
    };
  }

  /**
   * æ ¹æ“š setup é…ç½®ç”Ÿæˆ setup æª”æ¡ˆ
   */
  generateSetupFiles(setup) {
    const setupFiles = [];

    // 1. ç”Ÿæˆ package.jsonï¼ˆå¦‚æœæœ‰ npm ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.npm && setup.dependencies.npm.length > 0) {
      const packageJson = {
        name: "generated-project",
        version: "1.0.0",
        description: "Auto-generated project",
        scripts: {},
        dependencies: {}
      };

      // è§£æä¾è³´ï¼ˆæ”¯æ´ "express@4.18.0" å’Œ "express" æ ¼å¼ï¼‰
      setup.dependencies.npm.forEach(dep => {
        const [name, version] = dep.includes('@') && !dep.startsWith('@')
          ? dep.split('@')
          : [dep, 'latest'];
        packageJson.dependencies[name] = version;
      });

      // æ·»åŠ å•Ÿå‹•è…³æœ¬
      if (setup.startCommands && setup.startCommands.frontend) {
        packageJson.scripts.start = setup.startCommands.frontend;
      }
      if (setup.startCommands && setup.startCommands.backend) {
        packageJson.scripts.server = setup.startCommands.backend;
      }

      setupFiles.push({
        path: 'package.json',
        template: JSON.stringify(packageJson, null, 2),
        language: 'json'
      });
    }

    // 2. ç”Ÿæˆ requirements.txtï¼ˆå¦‚æœæœ‰ python ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.python && setup.dependencies.python.length > 0) {
      const requirementsTxt = setup.dependencies.python.join('\n');
      setupFiles.push({
        path: 'requirements.txt',
        template: requirementsTxt,
        language: 'text'
      });
    }

    // 3. ç”Ÿæˆ pom.xmlï¼ˆå¦‚æœæœ‰ maven ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.maven && setup.dependencies.maven.length > 0) {
      const pomXml = `<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <groupId>com.example</groupId>
    <artifactId>generated-project</artifactId>
    <version>1.0.0</version>
    
    <properties>
        <maven.compiler.source>${setup.javaVersion || '17'}</maven.compiler.source>
        <maven.compiler.target>${setup.javaVersion || '17'}</maven.compiler.target>
    </properties>
    
    <dependencies>
${setup.dependencies.maven.map(dep => {
        const [groupArtifact, version] = dep.split(':');
        const [groupId, artifactId] = groupArtifact.split('/');
        return `        <dependency>
            <groupId>${groupId}</groupId>
            <artifactId>${artifactId}</artifactId>
            <version>${version}</version>
        </dependency>`;
      }).join('\n')}
    </dependencies>
</project>`;
      setupFiles.push({
        path: 'pom.xml',
        template: pomXml,
        language: 'xml'
      });
    }

    // 4. ç”Ÿæˆ go.modï¼ˆå¦‚æœæœ‰ go ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.go && setup.dependencies.go.length > 0) {
      const goMod = `module generated-project

go ${setup.goVersion || '1.21'}

require (
${setup.dependencies.go.map(dep => `\t${dep}`).join('\n')}
)`;
      setupFiles.push({
        path: 'go.mod',
        template: goMod,
        language: 'text'
      });
    }

    // 5. ç”Ÿæˆ .env.exampleï¼ˆå¦‚æœæœ‰ç’°å¢ƒè®Šæ•¸ï¼‰
    if (setup.environmentVariables && Object.keys(setup.environmentVariables).length > 0) {
      const envExample = Object.entries(setup.environmentVariables)
        .map(([key, value]) => `${key}=${value}`)
        .join('\n');
      setupFiles.push({
        path: '.env.example',
        template: envExample,
        language: 'text'
      });
    }

    // 6. ç”Ÿæˆ README.md
    let readmeContent = '# Generated Project\n\n';

    if (setup.instructions) {
      readmeContent += `## Setup Instructions\n\n${setup.instructions}\n\n`;
    }

    if (setup.dependencies) {
      readmeContent += '## Dependencies\n\n';
      if (setup.dependencies.npm) {
        readmeContent += `**Node.js**: ${setup.nodeVersion || 'latest'}\n`;
        readmeContent += '```bash\nnpm install\n```\n\n';
      }
      if (setup.dependencies.python) {
        readmeContent += `**Python**: ${setup.pythonVersion || '3.8+'}\n`;
        readmeContent += '```bash\npip install -r requirements.txt\n```\n\n';
      }
      if (setup.dependencies.maven) {
        readmeContent += `**Java**: ${setup.javaVersion || '17+'}\n`;
        readmeContent += '```bash\nmvn clean install\n```\n\n';
      }
      if (setup.dependencies.go) {
        readmeContent += `**Go**: ${setup.goVersion || '1.21+'}\n`;
        readmeContent += '```bash\ngo mod download\n```\n\n';
      }
    }

    if (setup.startCommands) {
      readmeContent += '## Running the Project\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        readmeContent += `**${name}**:\n\`\`\`bash\n${command}\n\`\`\`\n\n`;
      });
    }

    if (setup.environmentVariables) {
      readmeContent += '## Environment Variables\n\n';
      readmeContent += 'Copy `.env.example` to `.env` and fill in the values:\n\n';
      Object.keys(setup.environmentVariables).forEach(key => {
        readmeContent += `- \`${key}\`\n`;
      });
    }

    setupFiles.push({
      path: 'README.md',
      template: readmeContent,
      language: 'markdown'
    });

    // 7. ç”Ÿæˆå•Ÿå‹•è…³æœ¬ start.sh / start.batï¼ˆå¦‚æœæœ‰ startCommandsï¼‰
    if (setup.startCommands) {
      // start.sh (Linux/Mac)
      let startSh = '#!/bin/bash\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        startSh += `echo "Starting ${name}..."\n${command} &\n\n`;
      });
      startSh += 'wait\n';
      setupFiles.push({
        path: 'start.sh',
        template: startSh,
        language: 'shell'
      });

      // start.bat (Windows)
      let startBat = '@echo off\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        startBat += `echo Starting ${name}...\nstart /B ${command}\n\n`;
      });
      setupFiles.push({
        path: 'start.bat',
        template: startBat,
        language: 'batch'
      });
    }

    return setupFiles;
  }

  // ===== Helper Methods =====

  /**
   * æŒ‰èªè¨€åˆ†çµ„æª”æ¡ˆ
   */
  groupFilesByLanguage(files) {
    const groups = {};

    files.forEach(file => {
      const lang = file.language || 'other';
      if (!groups[lang]) groups[lang] = [];
      groups[lang].push(file);
    });

    return groups;
  }

  /**
   * æ ¹æ“šæª”æ¡ˆè·¯å¾‘é¸æ“‡ worker agent
   */
  selectAgent(filePath) {
    const ext = path.extname(filePath).toLowerCase();
    const basename = path.basename(filePath).toLowerCase();

    // ç‰¹æ®Šæª”æ¡ˆåç¨±è™•ç†ï¼ˆæ²’æœ‰å‰¯æª”åçš„æª”æ¡ˆï¼‰
    if (basename === '.gitignore' || basename === '.env.example' || basename === 'dockerfile') {
      return this.workers.markup;
    }

    // requirements.txt ç‰¹åˆ¥è™•ç† â†’ ä½¿ç”¨ python-agent
    if (basename === 'requirements.txt') {
      return this.workers.python;
    }

    // æ ¹æ“šå‰¯æª”ååŒ¹é…
    for (const [name, worker] of Object.entries(this.workers)) {
      if (worker.exts.includes(ext)) {
        return worker;
      }
    }

    // é è¨­ä½¿ç”¨ markup agentï¼ˆæ”¹ç‚ºæ–‡å­—è™•ç†ï¼‰
    return this.workers.markup;
  }

  /**
   * å–å¾— agent åç¨±
   */
  getAgentName(agent) {
    for (const [name, worker] of Object.entries(this.workers)) {
      if (worker === agent) return name;
    }
    return 'unknown';
  }

  /**
   * å‘¼å«é›²ç«¯ API
   */
  async callCloudAPI(payload, requestId) {
    // Phase 1 éª¨æ¶ç”Ÿæˆï¼šä½¿ç”¨é›²ç«¯ API ç”Ÿæˆçµæ§‹åŒ–éª¨æ¶
    if (payload.task === 'generate_skeletons') {
      logger.info('Using Cloud API for skeleton generation', requestId);

      // å¦‚æœæ²’æœ‰é…ç½® APIï¼Œfallback åˆ° mock
      if (!this.CLOUD_API_ENDPOINT || !this.CLOUD_API_KEY) {
        logger.warn('Cloud API not configured, using mock for skeletons', requestId);
        return this.mockCloudAPI(payload, requestId);
      }

      // å‘¼å«é›²ç«¯ API ç”Ÿæˆéª¨æ¶
      try {
        return await this.generateSkeletonsViaAPI(payload, requestId);
      } catch (error) {
        logger.warn('Skeleton API call failed, falling back to mock', requestId, { error: error.message });
        return this.mockCloudAPI(payload, requestId);
      }
    }

    // Phase 2 ç´°ç¯€ç”Ÿæˆï¼šæ ¹æ“šé…ç½®æ±ºå®šä½¿ç”¨ mock é‚„æ˜¯ Worker Agents
    if (this.USE_MOCK_API) {
      return this.mockCloudAPI(payload, requestId);
    }

    // çœŸå¯¦ API å‘¼å«ï¼ˆç›®å‰ä¸æœƒåˆ°é”é€™è£¡ï¼Œå› ç‚º Phase 2 ç”¨ Worker Agentsï¼‰
    try {
      const apiUrl = this._getChatCompletionUrl(this.CLOUD_API_ENDPOINT);

      logger.info('Calling Cloud API', requestId, {
        url: apiUrl,
        model: 'gpt-5.1-codex-max' // Default assumption, adapter may override
      });

      const response = await this.fetchWithRetry(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.CLOUD_API_KEY}`,
          'X-Request-ID': requestId || 'no-request-id'
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Cloud API error: ${response.status} ${response.statusText} - ${errorText}`);
      }

      return await response.json();

    } catch (error) {
      logger.error('Cloud API call failed', requestId, { error: error.message });
      throw error;
    }
  }

  /**
   * Helper: Normalize and construct the Chat Completion URL
   * This handles various formats of OPENAI_BASE_URL to avoid 404s
   */
  _getChatCompletionUrl(baseUrl) {
    if (!baseUrl) return 'https://api.openai.com/v1/chat/completions';

    let url = baseUrl.trim();
    // Remove trailing slash
    if (url.endsWith('/')) {
      url = url.slice(0, -1);
    }

    // Case 1: Base URL already includes the full endpoint (e.g. from some proxies)
    if (url.endsWith('/chat/completions')) {
      return url;
    }

    // Case 2: Base URL ends with /v1
    if (url.endsWith('/v1')) {
      return `${url}/chat/completions`;
    }

    // Case 3: Just the domain or base path (e.g. https://api.openai.com)
    return `${url}/v1/chat/completions`;
  }

  /**
   * ä½¿ç”¨ Cloud API ç”Ÿæˆéª¨æ¶
   */
  async generateSkeletonsViaAPI(payload, requestId) {
    logger.info('Calling Cloud API to generate skeletons', requestId, {
      fileCount: payload.files.length
    });

    // å»ºæ§‹ promptï¼šè¦æ±‚ LLM ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„çµæ§‹åŒ–éª¨æ¶
    // å¦‚æœ payload åŒ…å« contractsï¼Œå‰‡å¼·åˆ¶éµå¾ªï¼›å¦å‰‡ç”± LLM æ¨æ–·ä¸€è‡´æ€§
    const hasContracts = payload.contracts && Object.keys(payload.contracts).length > 0;

    const systemPrompt = `You are an expert code architect. Generate structural skeletons for application files (web, mobile, backend, CLI, etc.).

Your task:
1. Generate file structure with:
   - Import statements
   - Function/class signatures
   - Type definitions
   - Key comments describing responsibilities
2. DO NOT implement logic - only structure
3. CRITICAL CONSISTENCY RULES (apply to ALL file types):
   - Cross-file references MUST be exact (HTML IDs â†’ CSS selectors â†’ JS querySelector)
   - Data attributes: HTML data-* values MUST match JS event handler checks exactly
   - Function names: HTML onclick/event references â†’ JS function names must match
   - File paths: <link>/<script> src â†’ actual file names must match
   - Variable naming: Shared concepts across files use consistent naming (camelCase in JS, snake_case in Python)
${hasContracts ? `
4. CONTRACT ENFORCEMENT (HIGHEST PRIORITY):
   The payload includes explicit contracts for cross-file communication.
   You MUST follow these contracts EXACTLY - no interpretation, no assumptions.
   
   For API contracts:
   - Include skeleton comments with EXACT request/response structure from contract
   - Frontend and backend MUST use IDENTICAL field names
   - Example: 
     /* API Contract: POST /api/orders
      * Request: { customer: {name: string, email: string}, items: [{productId: string, quantity: number}] }
      * Response: { orderId: string, total: number, status: string }
      */
   - Python: Use TypedDict/Pydantic models matching contract EXACTLY
   - JavaScript: Use JSDoc @typedef matching contract EXACTLY
   
   For module contracts:
   - Export functions MUST match signatures in contract
   - Import statements MUST reference correct module names
   
   For event contracts:
   - Event names and payload structures MUST match contract
   - dispatchEvent() and addEventListener() must use exact event names
   
   For storage contracts:
   - localStorage/sessionStorage keys MUST match contract
   - Data structures stored MUST match contract schema
   
   For class contracts:
   - Class fields and methods MUST match contract definition
   - Serialization methods (to_dict, toJSON) MUST follow contract structure
` : `
4. INFERRED CONSISTENCY (when no explicit contracts provided):
   - For API endpoints: Infer minimal REST-style payloads from descriptions
   - Document inferred structure in skeleton comments
   - Use standard conventions (e.g., {id, name, ...} for entities)
   - Keep structures simple and predictable
`}
5. Language-specific best practices:
   - HTML: Semantic tags, accessibility attributes
   - CSS: BEM naming, mobile-first, CSS Grid/Flexbox
   - JavaScript: ES6+, async/await, error handling
   - Python: Type hints, docstrings, PEP 8
   - Java: Interfaces, generics, JavaDoc
6. JSON OUTPUT REQUIREMENTS:
   - Output MUST be valid JSON array: [{"path": "...", "content": "..."}, ...]
   - For multi-line content, use actual newlines inside the JSON string (this is valid JSON)
   - You may wrap the JSON in markdown code block (triple backticks + json) for clarity
   - The content field should contain the code as-is without extra escaping
`;

    let userPrompt = `Generate skeletons for these files:

Project Requirements:
${payload.requirements || 'No specific requirements'}

Files to generate:
${payload.files.map((f, i) => `${i + 1}. ${f.path} (${f.type}): ${f.description}`).join('\n')}
`;

    // å¦‚æœæœ‰ contractsï¼Œé™„åŠ åˆ° prompt
    if (hasContracts) {
      userPrompt += `\n\n=== CONTRACTS (MUST FOLLOW EXACTLY) ===\n`;

      if (payload.contracts.api && payload.contracts.api.length > 0) {
        userPrompt += `\nAPI Endpoints:\n`;
        payload.contracts.api.forEach((api, i) => {
          userPrompt += `${i + 1}. ${api.endpoint} - ${api.description}\n`;
          userPrompt += `   Request: ${JSON.stringify(api.request, null, 2)}\n`;
          userPrompt += `   Response: ${JSON.stringify(api.response, null, 2)}\n`;
          userPrompt += `   Producers: ${api.producers.join(', ')}\n`;
          userPrompt += `   Consumers: ${api.consumers.join(', ')}\n\n`;
        });
      }

      if (payload.contracts.modules && payload.contracts.modules.length > 0) {
        userPrompt += `\nModules:\n`;
        payload.contracts.modules.forEach((mod, i) => {
          userPrompt += `${i + 1}. ${mod.name} (${mod.file})\n`;
          userPrompt += `   Exports: ${JSON.stringify(mod.exports, null, 2)}\n`;
          userPrompt += `   Importers: ${mod.importers.join(', ')}\n\n`;
        });
      }

      if (payload.contracts.events && payload.contracts.events.length > 0) {
        userPrompt += `\nCustom Events:\n`;
        payload.contracts.events.forEach((evt, i) => {
          userPrompt += `${i + 1}. ${evt.name} - ${evt.description}\n`;
          userPrompt += `   Payload: ${JSON.stringify(evt.payload, null, 2)}\n`;
          userPrompt += `   Emitters: ${evt.emitters.join(', ')}\n`;
          userPrompt += `   Listeners: ${evt.listeners.join(', ')}\n\n`;
        });
      }

      if (payload.contracts.storage && payload.contracts.storage.length > 0) {
        userPrompt += `\nStorage:\n`;
        payload.contracts.storage.forEach((store, i) => {
          userPrompt += `${i + 1}. ${store.key} (${store.type}) - ${store.description}\n`;
          userPrompt += `   Schema: ${JSON.stringify(store.schema, null, 2)}\n`;
          userPrompt += `   Writers: ${store.writers.join(', ')}\n`;
          userPrompt += `   Readers: ${store.readers.join(', ')}\n\n`;
        });
      }

      if (payload.contracts.classes && payload.contracts.classes.length > 0) {
        userPrompt += `\nShared Classes:\n`;
        payload.contracts.classes.forEach((cls, i) => {
          userPrompt += `${i + 1}. ${cls.name} (${cls.file})\n`;
          userPrompt += `   Fields: ${JSON.stringify(cls.fields, null, 2)}\n`;
          if (cls.methods) userPrompt += `   Methods: ${JSON.stringify(cls.methods, null, 2)}\n`;
          userPrompt += `   Consumers: ${cls.consumers.join(', ')}\n\n`;
        });
      }

      userPrompt += `\n=== END CONTRACTS ===\n`;
    }

    userPrompt += `
Generate structural skeletons following language conventions:
- HTML: DOCTYPE, head, body structure, script/link tags with correct file paths
- CSS: Selectors matching HTML classes/IDs
- JavaScript: Function signatures, class definitions, imports, event listeners
- Python: Class/function definitions, imports, type hints, route handlers
- Java: Package declarations, imports, class/interface definitions

${hasContracts ?
        'IMPORTANT: Follow the contracts EXACTLY. Every field name, type, and structure must match.' :
        'CONSISTENCY CHECK: Infer consistent structures across files. Every frontend API call should have a backend route.'}

IMPORTANT: Your response must be VALID JSON that can be parsed by JSON.parse().
Ensure all special characters are properly escaped according to JSON specification.
Do not include any text before or after the JSON array.

Return ONLY the JSON array, no markdown or explanation.`;

    try {
      // æª¢æ¸¬ API é¡å‹ï¼ˆGemini æˆ– OpenAIï¼‰
      const isGemini = this.CLOUD_API_ENDPOINT.includes('generativelanguage.googleapis.com');

      let requestBody, headers;

      if (isGemini) {
        // Gemini API æ ¼å¼
        requestBody = {
          contents: [{
            parts: [{
              text: `${systemPrompt}\n\n${userPrompt}`
            }]
          }],
          generationConfig: {
            temperature: 0.3,
            maxOutputTokens: 64000  // Gemini 2.5 Flash æ”¯æ´æœ€é«˜ 65536 tokens è¼¸å‡º
          }
        };

        headers = {
          'Content-Type': 'application/json'
        };

        // Gemini ä½¿ç”¨ query parameter èªè­‰
        let baseUrl = this.CLOUD_API_ENDPOINT;
        if (baseUrl.endsWith('/')) baseUrl = baseUrl.slice(0, -1);

        const model = 'gemini-2.5-pro'; // Coder Agent skeleton ç”Ÿæˆä½¿ç”¨
        const apiUrl = `${baseUrl}/models/${model}:generateContent?key=${this.CLOUD_API_KEY}`;

        const response = await this.fetchWithRetry(apiUrl, {
          method: 'POST',
          headers: headers,
          body: JSON.stringify(requestBody)
        }, requestId);

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`Gemini API error: ${response.status} - ${errorText}`);
        }

        const result = await response.json();
        const generatedText = result.candidates[0].content.parts[0].text;

        logger.info('Raw API response received', requestId, {
          textLength: generatedText.length,
          preview: generatedText.substring(0, 200)
        });

        // ç§»é™¤å¯èƒ½çš„ markdown code block åŒ…è£
        let cleanedText = generatedText.trim();
        if (cleanedText.startsWith('```json')) {
          cleanedText = cleanedText.replace(/^```json\s*\n/, '').replace(/\n```\s*$/, '');
        } else if (cleanedText.startsWith('```')) {
          cleanedText = cleanedText.replace(/^```\s*\n/, '').replace(/\n```\s*$/, '');
        }

        // è§£æ JSON
        const jsonMatch = cleanedText.match(/\[[\s\S]*\]/);
        if (!jsonMatch) {
          logger.error('No JSON array found in response', requestId, {
            fullText: cleanedText.substring(0, 2000)  // å¢åŠ é¡¯ç¤ºé•·åº¦
          });
          throw new Error('API response does not contain valid JSON array');
        }

        let skeletons;
        try {
          skeletons = JSON.parse(jsonMatch[0]);
        } catch (parseError) {
          logger.error('JSON parse failed', requestId, {
            error: parseError.message,
            jsonPreview: jsonMatch[0].substring(0, 1000),  // å¢åŠ é è¦½é•·åº¦
            jsonLength: jsonMatch[0].length
          });

          // å˜—è©¦ä¿®å¾©å¸¸è¦‹çš„è½‰ç¾©å•é¡Œ
          try {
            // ç§»é™¤å¤šé¤˜çš„åæ–œç·šè½‰ç¾©
            let fixedJson = jsonMatch[0]
              .replace(/\\\\\\\\/g, '\\')  // 4å€‹åæ–œç·š â†’ 1å€‹
              .replace(/\\\\\"/g, '"')     // 2å€‹åæ–œç·š+å¼•è™Ÿ â†’ å¼•è™Ÿ
              .replace(/\\\\n/g, '\\n');   // 2å€‹åæ–œç·š+n â†’ \n

            skeletons = JSON.parse(fixedJson);
            logger.info('JSON parse succeeded after fixing escaping', requestId);
          } catch (fixError) {
            logger.error('JSON fix attempt also failed', requestId, {
              fixError: fixError.message
            });
            throw new Error(`Failed to parse JSON: ${parseError.message}`);
          }
        }

        logger.info('Skeleton generation via API completed', requestId, {
          fileCount: skeletons.length,
          tokensUsed: result.usageMetadata?.totalTokenCount || 0
        });

        return { skeletons };

      } else {
        // OpenAI API æ ¼å¼
        // gpt-5.1-codex-max ä½¿ç”¨ v1/responses endpoint
        const apiUrl = `${this.CLOUD_API_ENDPOINT}/responses`;

        // Responses API ä½¿ç”¨ input (å­—ç¬¦ä¸²) è€Œé inputs (æ•¸çµ„)
        // éœ€è¦å°‡ system å’Œ user prompts åˆä½µç‚ºå–®ä¸€å­—ç¬¦ä¸²
        const combinedPrompt = `${systemPrompt}\n\nUser Request:\n${userPrompt}`;

        requestBody = {
          model: 'gpt-5.1-codex-max',
          input: combinedPrompt,
          temperature: 1
          // æ³¨æ„ï¼šResponses API ä¸æ”¯æŒ max_tokens åƒæ•¸
        };

        headers = {
          'Authorization': `Bearer ${this.CLOUD_API_KEY}`,
          'Content-Type': 'application/json'
        };

        logger.info('Calling OpenAI Responses API', requestId, {
          url: apiUrl,
          model: 'gpt-5.1-codex-max'
        });

        const response = await this.fetchWithRetry(apiUrl, {
          method: 'POST',
          headers,
          body: JSON.stringify(requestBody)
        }, requestId);

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
        }

        const data = await response.json();

        // Responses API éŸ¿æ‡‰æ ¼å¼
        let generatedText = '';

        // å¯¦éš›å…§å®¹åœ¨ output å­—æ®µä¸­
        if (data.output && Array.isArray(data.output) && data.output.length > 0) {
          // output æ˜¯ä¸€å€‹æ•¸çµ„ï¼Œéæ¿¾å‡º message é¡å‹çš„å…§å®¹
          const messageBlocks = data.output.filter(block => {
            if (typeof block === 'string') return true;
            if (typeof block === 'object' && block.type === 'message') return true;
            return false;
          });


          generatedText = messageBlocks
            .map(block => {
              if (typeof block === 'string') return block;
              if (typeof block === 'object') {
                // message å°è±¡çš„ content å¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€æ•¸çµ„æˆ–å°è±¡
                let content = block.content;

                // å¦‚æœ content æ˜¯æ•¸çµ„ï¼Œæå–æ‰€æœ‰ text å­—æ®µ
                if (Array.isArray(content)) {
                  return content
                    .map(item => {
                      if (typeof item === 'string') return item;
                      if (typeof item === 'object') {
                        return item.text || item.content || '';
                      }
                      return '';
                    })
                    .join('');
                }

                // å¦‚æœ content æ˜¯å°è±¡ï¼Œæå– text å­—æ®µ
                if (typeof content === 'object' && content !== null) {
                  return content.text || content.content || '';
                }

                // å¦‚æœ content æ˜¯å­—ç¬¦ä¸²
                if (typeof content === 'string') {
                  return content;
                }

                // å‚™ç”¨ï¼šå˜—è©¦ text å­—æ®µ
                return block.text || '';
              }
              return '';
            })
            .filter(text => text.length > 0)
            .join('');
        } else if (data.output && typeof data.output === 'object') {
          // output æ˜¯å–®å€‹å°è±¡
          if (data.output.text) {
            generatedText = data.output.text;
          } else if (data.output.content) {
            generatedText = data.output.content;
          } else {
            // å˜—è©¦åºåˆ—åŒ–æ•´å€‹å°è±¡
            generatedText = JSON.stringify(data.output);
          }
        } else if (data.output && typeof data.output === 'string') {
          generatedText = data.output;
        } else if (data.text && Array.isArray(data.text) && data.text.length > 0) {
          // å‚™ç”¨ï¼šå¦‚æœ text æ˜¯æ•¸çµ„
          generatedText = data.text
            .map(block => {
              if (typeof block === 'string') return block;
              return block.text || block.content || '';
            })
            .join('');
        } else if (data.text && typeof data.text === 'string') {
          generatedText = data.text;
        } else if (typeof data.output_text === 'string') {
          generatedText = data.output_text;
        } else if (data.choices && data.choices[0] && data.choices[0].message) {
          // Fallback to Chat Completions format
          generatedText = data.choices[0].message.content || '';
        } else {
          // è¨˜éŒ„è©³ç´°éŒ¯èª¤ä¿¡æ¯
          logger.error('Cannot extract text from response', requestId, {
            keys: Object.keys(data),
            hasOutput: 'output' in data,
            outputType: typeof data.output,
            outputIsArray: Array.isArray(data.output),
            hasText: 'text' in data,
            textType: typeof data.text,
            fullResponse: JSON.stringify(data).substring(0, 500)
          });
          throw new Error('Cannot extract text content from API response');
        }

        // ç¢ºä¿ç”Ÿæˆçš„æ–‡æœ¬ä¸æ˜¯ [object Object]
        if (generatedText === '[object Object]' || generatedText.includes('[object Object]')) {
          logger.error('Generated text contains [object Object]', requestId, {
            generatedText: generatedText.substring(0, 200),
            dataOutput: data.output ? JSON.stringify(data.output).substring(0, 200) : 'N/A'
          });
          throw new Error('Failed to properly extract text from response');
        }

        // ç¢ºä¿æ˜¯å­—ç¬¦ä¸²
        if (typeof generatedText !== 'string') {
          throw new Error(`Response is not a string: ${typeof generatedText}`);
        }

        // è§£æ JSON
        const jsonMatch = generatedText.match(/\[[\s\S]*\]/);
        if (!jsonMatch) {
          throw new Error('API response does not contain valid JSON array');
        }

        const skeletons = JSON.parse(jsonMatch[0]);

        logger.info('Skeleton generation via API completed', requestId, {
          fileCount: skeletons.length,
          tokensUsed: data.usage?.total_tokens || 0
        });

        return { skeletons };
      }

    } catch (error) {
      logger.error('Failed to generate skeletons via API', requestId, {
        error: error.message
      });
      throw error;
    }
  }

  /**
   * Mock Cloud APIï¼ˆç”¨æ–¼æ¸¬è©¦å’Œé–‹ç™¼ï¼‰
   */
  mockCloudAPI(payload, requestId) {
    logger.info('Using mock cloud API', requestId, { task: payload.task });

    if (payload.task === 'generate_skeletons') {
      // ç”Ÿæˆéª¨æ¶çš„ mock å›æ‡‰
      const skeletons = payload.files.map(file => {
        const skeleton = this.generateMockSkeleton(file);
        return {
          path: file.path,
          content: skeleton
        };
      });

      return Promise.resolve({ skeletons });

    } else if (payload.task === 'fill_details') {
      // ç”Ÿæˆç´°ç¯€çš„ mock å›æ‡‰
      const content = this.generateMockDetailedContent(payload.context);
      return Promise.resolve({
        content: content,
        metadata: {
          tokens_used: Math.floor(Math.random() * 3000) + 1000,
          model: 'mock-model-v1'
        }
      });
    }

    return Promise.reject(new Error(`Unknown mock task: ${payload.task}`));
  }

  /**
   * ç”Ÿæˆ mock éª¨æ¶
   */
  generateMockSkeleton(file) {
    const ext = path.extname(file.path).toLowerCase();

    switch (ext) {
      case '.html':
      case '.htm':
        return `<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>${file.description || 'Page'}</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- TODO: Implement ${file.description || 'content'} -->
</body>
</html>`;

      case '.css':
      case '.scss':
        return `/* ${file.description || 'Styles'} */

/* TODO: Implement styles */
body {
    margin: 0;
    padding: 0;
}`;

      case '.js':
      case '.jsx':
        return `// ${file.description || 'JavaScript Module'}

// TODO: Implement functionality
export class App {
    constructor() {
        // TODO: Initialize
    }
    
    init() {
        // TODO: Setup
    }
}`;

      case '.py':
        return `"""
${file.description || 'Python Module'}
"""

# TODO: Implement functionality

class App:
    """Main application class"""
    
    def __init__(self):
        """Initialize the application"""
        pass
    
    def run(self):
        """Run the application"""
        pass`;

      default:
        return `// ${file.description || 'Module'}\n\n// TODO: Implement ${file.path}`;
    }
  }

  /**
   * ç”Ÿæˆ mock è©³ç´°å…§å®¹ï¼ˆç°¡å–®æ“´å……éª¨æ¶ï¼‰
   */
  generateMockDetailedContent(context) {
    if (!context || !context.skeleton) {
      return '// Error: No skeleton provided';
    }

    // ç°¡å–®åœ°åœ¨éª¨æ¶å¾Œé¢æ·»åŠ ä¸€äº›å¯¦ä½œ
    const skeleton = context.skeleton;
    const fileSpec = context.fileSpec || {};

    return skeleton.replace(/TODO: Implement/g, 'IMPLEMENTED (mock)')
      .replace(/TODO: /g, '')
      + `\n\n// Generated with mock API for ${fileSpec.path}\n`;
  }

  /**
   * ç”Ÿæˆæª”æ¡ˆç´°ç¯€ï¼ˆå‘¼å« worker agentï¼‰
   */
  async generateFileDetail(agent, fileSpec, context, requestId) {
    const agentName = this.getAgentName(agent);

    try {
      logger.debug(`Calling ${agentName} generator for ${fileSpec.path}`, requestId);

      // æº–å‚™è«‹æ±‚åƒæ•¸
      const params = {
        skeleton: context.skeleton || '',
        fileSpec: context.fileSpec,
        context: {
          completedFiles: context.completedFiles || [],
          dependencies: context.dependencies || [],
          allFiles: context.allFiles || [],
          allSkeletons: context.allSkeletons || {},
          contracts: context.contracts || null,
          projectConfig: context.projectConfig || null
        }
      };

      // ç›´æ¥èª¿ç”¨æœ¬åœ° generator
      const result = await agent.generator.generate(params);

      if (!result || !result.content) {
        throw new Error(`Generator returned invalid result`);
      }

      logger.debug(`âœ“ ${agentName} generated ${fileSpec.path}`, requestId, {
        tokens: result.tokensUsed,
        method: result.method,
        size: result.content.length
      });

      // çµ±ä¸€è¿”å›æ ¼å¼
      return {
        success: true,
        content: result.content,
        metadata: {
          tokens_used: result.tokensUsed,
          method: result.method,
          agent: agentName
        }
      };

    } catch (error) {
      logger.error(`Worker generator ${agentName} error`, requestId, {
        error: error.message,
        file: fileSpec.path
      });

      // Fallback åˆ°éª¨æ¶
      return {
        success: false,
        content: context.skeleton || `// Error generating ${fileSpec.path}: ${error.message}`,
        metadata: {
          error: error.message,
          fallback: 'skeleton'
        }
      };
    }
  }

  /**
   * å»¶é²å‡½æ•¸
   */
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Fetch with retry logic for 502/503/504 errors
   */
  async fetchWithRetry(url, options, requestId, retries = 3, backoff = 1000) {
    for (let i = 0; i < retries + 1; i++) {
      try {
        const response = await fetch(url, options);

        // If successful or client error (4xx), return immediately
        if (response.ok || response.status < 500) {
          return response;
        }

        // If server error (5xx) and we have retries left
        if (i < retries) {
          const delay = backoff * Math.pow(2, i); // Exponential backoff
          logger.warn(`API request failed with ${response.status}, retrying in ${delay}ms...`, requestId, {
            attempt: i + 1,
            maxRetries: retries
          });
          await this.sleep(delay);
          continue;
        }

        return response;

      } catch (error) {
        // Network errors (e.g. DNS, connection refused)
        if (i < retries) {
          const delay = backoff * Math.pow(2, i);
          logger.warn(`API request network error: ${error.message}, retrying in ${delay}ms...`, requestId, {
            attempt: i + 1,
            maxRetries: retries
          });
          await this.sleep(delay);
        } else {
          throw error;
        }
      }
    }
  }
}

module.exports = Coordinator;
