/**
 * Coordinator - å”èª¿éª¨æ¶ç”Ÿæˆå’Œç´°ç¯€å¡«å……çš„æ ¸å¿ƒé‚è¼¯
 * 
 * æµç¨‹:
 * 1. Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆå–®æ¬¡æˆ–åˆ†æ‰¹ API å‘¼å«ï¼‰
 * 2. Phase 2: åºåˆ—åŒ–ç”Ÿæˆæ¯å€‹æª”æ¡ˆçš„ç´°ç¯€ï¼ˆä¸€æ¬¡ä¸€å€‹ agentï¼Œç¢ºä¿æ­£ç¢ºæ€§ï¼‰
 * 3. Phase 3: çµ„è£å’Œé©—è­‰æœ€çµ‚çµæœ
 */

// è¼‰å…¥ dotenv ä»¥è®€å– .env æ–‡ä»¶ä¸­çš„ç’°å¢ƒè®Šæ•¸
// å¾ç•¶å‰æ–‡ä»¶ä½ç½®å‘ä¸ŠæŸ¥æ‰¾é …ç›®æ ¹ç›®éŒ„çš„ .env æ–‡ä»¶
const path = require('path');
const fs = require('fs');

// å˜—è©¦å¤šå€‹å¯èƒ½çš„ .env æ–‡ä»¶è·¯å¾‘
const possibleEnvPaths = [
  path.resolve(__dirname, '../../.env'),  // å¾ coordinator.cjs å‘ä¸Šå…©ç´š
  path.resolve(process.cwd(), '.env'),    // å¾ç•¶å‰å·¥ä½œç›®éŒ„
  path.join(__dirname, '../../.env'),     // ç›¸å°è·¯å¾‘
];

let envPath = null;
for (const possiblePath of possibleEnvPaths) {
  if (fs.existsSync(possiblePath)) {
    envPath = possiblePath;
    break;
  }
}

if (envPath) {
  const result = require('dotenv').config({ path: envPath });
  if (result.error) {
    console.warn(`[Coordinator] Failed to load .env from ${envPath}:`, result.error.message);
  } else {
    console.log(`[Coordinator] Loaded .env from: ${envPath}`);
  }
} else {
  // å¦‚æœæ‰¾ä¸åˆ° .env æ–‡ä»¶ï¼Œå˜—è©¦å¾ç•¶å‰ç›®éŒ„è¼‰å…¥ï¼ˆdotenv é»˜èªè¡Œç‚ºï¼‰
  require('dotenv').config();
  console.warn(`[Coordinator] .env file not found in expected locations, using default dotenv behavior`);
}

const logger = require('../shared/logger.cjs');
const DependencyAnalyzer = require('./dependency-analyzer');
const ConfigGenerator = require('./config-generator');

// ContentGenerators will be loaded dynamically when needed (ES module)
let ContentGeneratorsPromise = null;

async function loadContentGenerators() {
  if (ContentGeneratorsPromise) {
    return ContentGeneratorsPromise;
  }
  
  ContentGeneratorsPromise = (async () => {
    try {
      // Use dynamic import for ES module
      const generatorsModule = await import('../generators/index.js');
      return generatorsModule.default || generatorsModule;
    } catch (e) {
      logger.warn('Could not load ContentGenerators, using basic mock generation', null, {
        error: e.message
      });
      return null;
    }
  })();
  
  return ContentGeneratorsPromise;
}

// Polyfill for fetch (Node.js < 18)
const fetch = global.fetch || (async function(...args) {
  const https = require('https');
  const http = require('http');
  const url = args[0];
  const options = args[1] || {};
  
  return new Promise((resolve, reject) => {
    const urlObj = new URL(url);
    const protocol = urlObj.protocol === 'https:' ? https : http;
    
    const req = protocol.request(url, {
      method: options.method || 'GET',
      headers: options.headers || {}
    }, (res) => {
      let data = '';
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        resolve({
          ok: res.statusCode >= 200 && res.statusCode < 300,
          status: res.statusCode,
          statusText: res.statusMessage,
          json: () => Promise.resolve(JSON.parse(data)),
          text: () => Promise.resolve(data)
        });
      });
    });
    
    req.on('error', reject);
    
    if (options.body) {
      req.write(options.body);
    }
    
    req.end();
  });
});

class Coordinator {
  constructor(config = {}) {
    // ä¾è³´åˆ†æå™¨
    this.dependencyAnalyzer = new DependencyAnalyzer();
    
    // Worker agents é…ç½®ï¼ˆæœªä¾†å¯¦ä½œæ™‚ä½¿ç”¨ï¼‰
    this.workers = {
      'markup': { 
        endpoint: config.markupEndpoint || 'http://localhost:3801/generate', 
        exts: ['.html', '.xml', '.md', '.htm'] 
      },
      'style': { 
        endpoint: config.styleEndpoint || 'http://localhost:3802/generate', 
        exts: ['.css', '.scss', '.sass', '.less'] 
      },
      'script': { 
        endpoint: config.scriptEndpoint || 'http://localhost:3803/generate', 
        exts: ['.js', '.ts', '.jsx', '.tsx', '.mjs', '.cjs'] 
      },
      'python': { 
        endpoint: config.pythonEndpoint || 'http://localhost:3804/generate', 
        exts: ['.py'] 
      },
      'system': { 
        endpoint: config.systemEndpoint || 'http://localhost:3805/generate', 
        exts: ['.c', '.cpp', '.h', '.hpp', '.go', '.rs', '.java', '.cs'] 
      }
    };
    
    // é…ç½®åƒæ•¸
    this.MAX_FILES_PER_SKELETON_BATCH = config.maxSkeletonBatch || 15;
    this.DETAIL_GENERATION_DELAY = config.detailDelay || 1500; // æ¯«ç§’
    
    // æ”¯æŒå¤šç¨®ç’°å¢ƒè®Šæ•¸åç¨±ï¼ˆCLOUD_API_* æˆ– OPENAI_*ï¼‰
    // å„ªå…ˆä½¿ç”¨ Geminiï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨ OpenAI
    let endpoint = config.cloudApiEndpoint || 
      process.env.CLOUD_API_ENDPOINT || 
      process.env.OPENAI_BASE_URL ||
      null;
    
    // é…ç½® Gemini APIï¼ˆå„ªå…ˆï¼‰
    this.GEMINI_API_ENDPOINT = process.env.GEMINI_BASE_URL || 'https://generativelanguage.googleapis.com/v1beta';
    this.GEMINI_API_KEY = process.env.GEMINI_API_KEY;
    this.GEMINI_MODEL = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
    
    // é…ç½® OpenAI APIï¼ˆå‚™ç”¨ï¼‰
    // å¦‚æœç«¯é»æ˜¯ OpenAI åŸºç¤ URLï¼Œè‡ªå‹•æ·»åŠ  chat/completions è·¯å¾‘
    if (endpoint && endpoint.includes('api.openai.com')) {
      // å¦‚æœå·²ç¶“æ˜¯å®Œæ•´ç«¯é»ï¼ˆåŒ…å« /chat/completionsï¼‰ï¼Œä¿æŒä¸è®Š
      if (endpoint.includes('/chat/completions')) {
        // å·²ç¶“æ˜¯å®Œæ•´ç«¯é»ï¼Œä¸éœ€è¦ä¿®æ”¹
      } else if (endpoint.includes('/v1')) {
        // å¦‚æœæ˜¯ /v1 çµå°¾ï¼ˆå¦‚ https://api.openai.com/v1ï¼‰ï¼Œæ·»åŠ  /chat/completions
        endpoint = endpoint.endsWith('/') 
          ? endpoint + 'chat/completions' 
          : endpoint + '/chat/completions';
      } else {
        // å¦‚æœåªæ˜¯åŸºç¤ URLï¼ˆå¦‚ https://api.openai.comï¼‰ï¼Œæ·»åŠ  /v1/chat/completions
        endpoint = endpoint.endsWith('/') 
          ? endpoint + 'v1/chat/completions' 
          : endpoint + '/v1/chat/completions';
      }
    }
    
    // å¦‚æœæ²’æœ‰ç«¯é»ä½†æœ‰ API Keyï¼Œä½¿ç”¨é»˜èªçš„ OpenAI ç«¯é»
    if (!endpoint && (process.env.OPENAI_API_KEY || process.env.CLOUD_API_KEY)) {
      endpoint = 'https://api.openai.com/v1/chat/completions';
    }
    
    this.OPENAI_API_ENDPOINT = endpoint;
    this.OPENAI_API_KEY = config.cloudApiKey || 
      process.env.CLOUD_API_KEY || 
      process.env.OPENAI_API_KEY;
    
    // ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œä¿ç•™èˆŠçš„è®Šæ•¸åï¼ˆå„ªå…ˆä½¿ç”¨ Geminiï¼‰
    this.CLOUD_API_ENDPOINT = this.GEMINI_API_KEY ? 
      `${this.GEMINI_API_ENDPOINT}/models/${this.GEMINI_MODEL}:generateContent` : 
      this.OPENAI_API_ENDPOINT;
    this.CLOUD_API_KEY = this.GEMINI_API_KEY || this.OPENAI_API_KEY;
    
    // é è¨­ä½¿ç”¨ Worker Agentsï¼ˆå¦‚æœæ˜ç¢ºè¦æ±‚ä½¿ç”¨ mock æ‰ç”¨ mockï¼‰
    this.USE_MOCK_API = config.useMockApi === true;
    
    // èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥ç’°å¢ƒè®Šæ•¸æ˜¯å¦è¢«è®€å–
    const hasEndpoint = !!(this.CLOUD_API_ENDPOINT);
    const hasKey = !!(this.CLOUD_API_KEY);
    const endpointPreview = this.CLOUD_API_ENDPOINT ? 
      (this.CLOUD_API_ENDPOINT.length > 50 ? this.CLOUD_API_ENDPOINT.substring(0, 50) + '...' : this.CLOUD_API_ENDPOINT) : 
      'not set';
    const keyPreview = this.CLOUD_API_KEY ? 
      (this.CLOUD_API_KEY.length > 10 ? this.CLOUD_API_KEY.substring(0, 10) + '...' : '***') : 
      'not set';
    
    logger.info('Coordinator initialized', null, {
      use_mock_api: this.USE_MOCK_API,
      worker_agents: Object.keys(this.workers).length,
      max_skeleton_batch: this.MAX_FILES_PER_SKELETON_BATCH,
      cloud_api_configured: hasEndpoint && hasKey,
      cloud_api_endpoint: endpointPreview,
      cloud_api_key_set: hasKey,
      env_endpoint: process.env.CLOUD_API_ENDPOINT ? 'set' : 'not set',
      env_key: process.env.CLOUD_API_KEY ? 'set' : 'not set'
    });
  }

  /**
   * ä¸»å…¥å£ï¼šå¾ architect payload ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆ
   */
  async generateFromArchitectPayload(payload, requestId = null) {
    const coderInstructions = payload.output.coder_instructions;
    const files = coderInstructions.files;
    const contracts = coderInstructions.contracts || null; // å¯é¸çš„ contracts
    
    logger.info('Coordinator starting', requestId, { 
      totalFiles: files.length,
      hasContracts: !!contracts,
      hasProjectConfig: !!coderInstructions.projectConfig,
      useMockApi: this.USE_MOCK_API 
    });

    try {
      // Phase 0: è‡ªå‹•ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
      logger.info('Phase 0: Generating config files', requestId);
      const configFiles = ConfigGenerator.generateAll(coderInstructions);
      if (configFiles.length > 0) {
        logger.info('Config files generated', requestId, {
          files: configFiles.map(f => f.path)
        });
        // å°‡é…ç½®æ–‡ä»¶åŠ å…¥åˆ°æ–‡ä»¶åˆ—è¡¨ä¸­
        files.unshift(...configFiles);
      }
      
      // Phase 0.5: æª¢æ¸¬æ˜¯å¦éœ€è¦ç”Ÿæˆå‰ç«¯æª”æ¡ˆ
      logger.info('Phase 0.5: Checking for frontend files', requestId);
      const frontendFiles = this.generateFrontendFilesIfNeeded(files, coderInstructions);
      if (frontendFiles.length > 0) {
        logger.info('Frontend files generated', requestId, {
          files: frontendFiles.map(f => f.path)
        });
        // å°‡å‰ç«¯æª”æ¡ˆåŠ å…¥åˆ°æ–‡ä»¶åˆ—è¡¨ä¸­
        files.push(...frontendFiles);
      }
      
      // Phase 1: ç”Ÿæˆéª¨æ¶ï¼ˆå‚³éå®Œæ•´çš„ coder_instructions åŒ…å« contractsï¼‰
      logger.info('Phase 1: Generating skeletons', requestId);
      const skeletons = await this.generateAllSkeletons(coderInstructions, requestId);
      
      // Phase 2: åºåˆ—åŒ–ç”Ÿæˆç´°ç¯€ï¼ˆå‚³é contracts å’Œå®Œæ•´çš„ coderInstructionsï¼‰
      logger.info('Phase 2: Generating details sequentially', requestId);
      const detailedFiles = await this.generateDetailsSequentially(files, skeletons, contracts, requestId, coderInstructions);
      
      // Phase 3: çµ„è£ï¼ˆå‚³é payload ä»¥ä¾¿ç”Ÿæˆ setup æª”æ¡ˆï¼‰
      logger.info('Phase 3: Assembling results', requestId);
      const result = await this.assemble(detailedFiles, skeletons, requestId, payload.output);
      
      logger.info('Coordinator completed', requestId, { 
        filesGenerated: result.files.length,
        configFiles: configFiles.length,
        successful: detailedFiles.filter(f => !f.error).length,
        failed: detailedFiles.filter(f => f.error).length
      });
      
      return result;
      
    } catch (error) {
      logger.error('Coordinator failed', requestId, { 
        error: error.message, 
        stack: error.stack 
      });
      throw error;
    }
  }

  /**
   * Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆè‡ªå‹•åˆ†æ‰¹ï¼‰
   */
  /**
   * Phase 1: ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„éª¨æ¶ï¼ˆè‡ªå‹•åˆ†æ‰¹ï¼‰
   * @param {Object} coderInstructions - åŒ…å« files, requirements, contracts, summary
   */
  async generateAllSkeletons(coderInstructions, requestId) {
    const files = Array.isArray(coderInstructions) ? coderInstructions : coderInstructions.files;
    logger.info('Generating skeletons with auto-batching', requestId, { 
      totalFiles: files.length 
    });
    
    // ç›´æ¥å‘¼å« generateSkeletonsBatchï¼Œå®ƒæœƒè‡ªå‹•æ±ºå®šæ˜¯å¦åˆ†æ‰¹
    // å‚³éå®Œæ•´çš„ coderInstructionsï¼ˆåŒ…å« contracts, summary, requirementsï¼‰
    // ä¿å­˜ coderInstructions ä»¥ä¾¿åœ¨ generateSkeletonsViaAPI ä¸­ä½¿ç”¨
    this.currentCoderInstructions = coderInstructions;
    return await this.generateSkeletonsBatch(coderInstructions, requestId);
  }

  /**
   * å–®æ¬¡æˆ–åˆ†æ‰¹ç”Ÿæˆéª¨æ¶ï¼ˆè‡ªå‹•æª¢æ¸¬æ˜¯å¦éœ€è¦åˆ†æ‰¹ï¼‰
   * @param {Object|Array} coderInstructions - å¯ä»¥æ˜¯ {files, contracts} æˆ–ç´” files[]
   */
  async generateSkeletonsBatch(coderInstructions, requestId) {
    const MAX_FILES_PER_BATCH = 5;  // æ¯æ‰¹æœ€å¤š 5 å€‹æª”æ¡ˆï¼ˆé¿å… token è¶…é™ï¼‰
    
    // ç›¸å®¹èˆŠæ ¼å¼ï¼šå¦‚æœå‚³å…¥çš„æ˜¯é™£åˆ—ï¼Œè½‰æ›æˆç‰©ä»¶
    const payload = Array.isArray(coderInstructions) 
      ? { files: coderInstructions } 
      : coderInstructions;
    
    const files = payload.files;
    
    // å¦‚æœæª”æ¡ˆæ•¸ <= 5ï¼Œå–®æ¬¡ç”Ÿæˆ
    if (files.length <= MAX_FILES_PER_BATCH) {
      logger.info('Calling cloud API for skeleton generation (single batch)', requestId, { 
        fileCount: files.length 
      });
      
      return await this.generateSkeletonsSingleBatch(payload, requestId);
    }
    
    // å¦å‰‡åˆ†æ‰¹ç”Ÿæˆ
    logger.info('Files exceed batch limit, splitting into multiple batches', requestId, { 
      totalFiles: files.length,
      batchSize: MAX_FILES_PER_BATCH
    });
    
    const skeletonMap = {};
    
    // æŒ‰èªè¨€åˆ†çµ„ï¼ˆåŒé¡å‹æª”æ¡ˆæ”¾ä¸€èµ·ï¼‰
    const batches = [];
    const byLanguage = {};
    
    files.forEach(f => {
      const lang = f.language || 'unknown';
      if (!byLanguage[lang]) byLanguage[lang] = [];
      byLanguage[lang].push(f);
    });
    
    // å°‡æ¯å€‹èªè¨€çš„æª”æ¡ˆåˆ†æˆå°æ‰¹æ¬¡
    Object.values(byLanguage).forEach(langFiles => {
      for (let i = 0; i < langFiles.length; i += MAX_FILES_PER_BATCH) {
        batches.push(langFiles.slice(i, i + MAX_FILES_PER_BATCH));
      }
    });
    
    logger.info('Created batches for skeleton generation', requestId, {
      totalBatches: batches.length,
      batchSizes: batches.map(b => b.length)
    });
    
    // é€æ‰¹ç”Ÿæˆ
    for (let i = 0; i < batches.length; i++) {
      logger.info(`Processing skeleton batch ${i + 1}/${batches.length}`, requestId, {
        filesInBatch: batches[i].length,
        files: batches[i].map(f => f.path)
      });
      
      // æ¯å€‹ batch ä¹Ÿå‚³é contractsï¼ˆå¦‚æœæœ‰ï¼‰
      const batchPayload = {
        files: batches[i],
        contracts: payload.contracts || null,
        requirements: payload.requirements || null
      };
      
      const batchSkeletons = await this.generateSkeletonsSingleBatch(batchPayload, requestId);
      Object.assign(skeletonMap, batchSkeletons);
      
      // æ‰¹æ¬¡é–“å»¶é²ï¼ˆé¿å… API rate limitï¼‰
      if (i < batches.length - 1) {
        logger.info(`Waiting before next batch...`, requestId);
        await this.sleep(2000);
      }
    }
    
    logger.info('All skeleton batches completed', requestId, {
      totalSkeletons: Object.keys(skeletonMap).length
    });
    
    return skeletonMap;
  }

  /**
   * å–®æ¬¡ API å‘¼å«ç”Ÿæˆéª¨æ¶ï¼ˆä¸åˆ†æ‰¹ï¼‰
   * @param {Object} payload - åŒ…å« files, contracts, requirements
   */
  async generateSkeletonsSingleBatch(payload, requestId) {
    // ç›¸å®¹èˆŠæ ¼å¼ï¼šå¦‚æœå‚³å…¥çš„æ˜¯é™£åˆ—ï¼Œè½‰æ›æˆç‰©ä»¶
    if (Array.isArray(payload)) {
      payload = { files: payload };
    }
    
    const files = payload.files;
    
    logger.info('Calling cloud API for skeleton generation', requestId, { 
      fileCount: files.length 
    });
    
    // æº–å‚™ API payload
    const apiPayload = {
      task: 'generate_skeletons',
      instructions: 'Generate code skeletons for all specified files. Include only structure, imports, and signatures. NO implementation details.',
      files: payload.files.map(f => ({
        path: f.path,
        language: f.language,
        description: f.description || '',
        requirements: Array.isArray(f.requirements) ? f.requirements : []
      })),
      constraints: {
        output_format: 'skeleton_only',
        include: ['imports', 'exports', 'class_signatures', 'function_signatures', 'type_definitions', 'docstrings'],
        exclude: ['implementation', 'detailed_logic', 'inline_comments', 'test_code']
      }
    };

    // å‘¼å«é›²ç«¯ API
    const response = await this.callCloudAPI(apiPayload, requestId);

    // è§£æå›å‚³çš„éª¨æ¶
    const skeletonMap = {};
    
    if (response.skeletons && Array.isArray(response.skeletons)) {
      logger.info('Processing skeleton response', requestId, {
        receivedCount: response.skeletons.length,
        expectedCount: files.length
      });
      
      response.skeletons.forEach(skeleton => {
        if (skeleton.path && skeleton.content) {
          skeletonMap[skeleton.path] = skeleton.content;
          logger.debug(`âœ“ Skeleton for ${skeleton.path}`, requestId, {
            contentLength: skeleton.content.length
          });
        } else {
          logger.warn(`âš  Invalid skeleton entry`, requestId, { skeleton });
        }
      });
      
      // æª¢æŸ¥æ˜¯å¦æœ‰æª”æ¡ˆç¼ºå°‘éª¨æ¶ï¼Œç‚ºç¼ºå°‘çš„æª”æ¡ˆç”ŸæˆåŸºæœ¬éª¨æ¶
      const missing = files.filter(f => !skeletonMap[f.path]);
      if (missing.length > 0) {
        logger.warn('Some files missing skeletons, generating fallback skeletons', requestId, {
          missingFiles: missing.map(f => f.path),
          receivedSkeletons: Object.keys(skeletonMap)
        });
        
        // ç‚ºç¼ºå°‘çš„æª”æ¡ˆç”ŸæˆåŸºæœ¬éª¨æ¶
        missing.forEach(file => {
          skeletonMap[file.path] = this.generateMockSkeleton(file);
          logger.info(`Generated fallback skeleton for ${file.path}`, requestId);
        });
      }
    } else {
      logger.warn('Invalid skeleton response format, generating all skeletons from mock', requestId, { response });
      
      // å¦‚æœå›æ‡‰æ ¼å¼ç„¡æ•ˆï¼Œç‚ºæ‰€æœ‰æª”æ¡ˆç”Ÿæˆ mock éª¨æ¶
      files.forEach(file => {
        if (!skeletonMap[file.path]) {
          skeletonMap[file.path] = this.generateMockSkeleton(file);
        }
      });
    }

    // ç¢ºä¿æ‰€æœ‰æª”æ¡ˆéƒ½æœ‰éª¨æ¶
    files.forEach(file => {
      if (!skeletonMap[file.path]) {
        logger.warn(`No skeleton for ${file.path}, generating fallback`, requestId);
        skeletonMap[file.path] = this.generateMockSkeleton(file);
    }
    });

    logger.info('Skeletons generated successfully', requestId, { 
      count: Object.keys(skeletonMap).length,
      files: Object.keys(skeletonMap),
      totalExpected: files.length
    });
    
    return skeletonMap;
  }

  /**
   * Phase 2: æ ¹æ“šä¾è³´é—œä¿‚ç”Ÿæˆç´°ç¯€ï¼ˆä½µç™¼æˆ–åºåˆ—ï¼‰
   */
  /**
   * Phase 2: åºåˆ—åŒ–ç”Ÿæˆç´°ç¯€ï¼ˆä¾è³´åˆ†å±¤ï¼Œå±¤å…§ä½µç™¼ï¼‰
   * @param {Array} files - æª”æ¡ˆåˆ—è¡¨
   * @param {Object} skeletons - éª¨æ¶å°æ‡‰è¡¨
   * @param {Object} contracts - å¯é¸çš„è·¨æª”æ¡ˆ contracts
   * @param {Object} coderInstructions - å®Œæ•´çš„ coder instructionsï¼ˆåŒ…å« summary, requirements ç­‰ï¼‰
   */
  async generateDetailsSequentially(files, skeletons, contracts, requestId, coderInstructions = {}) {
    // åˆ†ææª”æ¡ˆä¾è³´é—œä¿‚
    const { order, groups, depGraph } = this.dependencyAnalyzer.analyze(files, requestId);
    
    // è¦–è¦ºåŒ–ä¾è³´é—œä¿‚ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
    this.dependencyAnalyzer.visualizeDependencies(depGraph, groups, requestId);
    
    logger.info('Starting layered detail generation', requestId, { 
      totalFiles: files.length,
      layers: groups.length,
      strategy: groups.length === 1 ? 'all-concurrent' : 'layered-concurrent',
      hasContracts: !!contracts
    });

    const results = [];
    const fileMap = {};
    files.forEach(f => { fileMap[f.path] = f; });

    // é€å±¤ç”Ÿæˆï¼ˆæ¯å±¤å…§éƒ¨ä½µç™¼ï¼Œå±¤èˆ‡å±¤ä¹‹é–“åºåˆ—ï¼‰
    for (let layerIdx = 0; layerIdx < groups.length; layerIdx++) {
      const layer = groups[layerIdx];
      const isLastLayer = layerIdx === groups.length - 1;
      
      logger.info(`Processing Layer ${layerIdx + 1}/${groups.length}`, requestId, {
        filesInLayer: layer.length,
        files: layer.map(p => path.basename(p))
      });

      // å±¤å…§ä½µç™¼ç”Ÿæˆ
      const layerPromises = layer.map(async (filePath) => {
        const file = fileMap[filePath];
        
        // ğŸ”’ è·³éè‡ªå‹•ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ï¼ˆç›´æ¥ä½¿ç”¨ ConfigGenerator çš„æ¨¡æ¿ï¼‰
        if (file.isAutoGenerated && file.content) {
          logger.info(`â­ Skipping AI generation for ${file.path} (using template)`, requestId);
          return {
            path: file.path,
            content: file.content,
            language: file.type,
            metadata: { skipped: true, reason: 'auto-generated config file' }
          };
        }
        
        const agent = this.selectAgent(file.path);
        const agentName = this.getAgentName(agent);
        
        try {
          // å»ºç«‹ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å·²å®Œæˆçš„ä¾è³´æª”æ¡ˆ + contractsï¼‰
          const deps = depGraph[filePath] || [];
          const completedDeps = results
            .filter(r => !r.error && deps.includes(r.path))
            .map(r => ({ path: r.path, content: r.content, language: r.language }));
          
          const fileSkeleton = skeletons[file.path];
          if (!fileSkeleton) {
            logger.warn(`âš  No skeleton found for ${file.path}`, requestId);
          }
          
          const context = {
            skeleton: fileSkeleton,
            allSkeletons: skeletons,
            completedFiles: results
              .filter(r => !r.error)
              .map(r => ({ path: r.path, content: r.content, language: r.language })),
            dependencies: completedDeps,
            allFiles: files, // å‚³éæ‰€æœ‰æª”æ¡ˆè³‡è¨Šï¼ˆç”¨æ–¼é çŸ¥å°‡ä¾†çš„æª”æ¡ˆï¼‰
            contracts: contracts || null, // â† æ–°å¢ï¼šå‚³é contracts çµ¦ Worker Agents
            // å‚³éå®Œæ•´çš„ç”¨æˆ¶éœ€æ±‚å’Œé …ç›®ä¿¡æ¯
            userRequirement: coderInstructions.summary || coderInstructions.requirements || '',
            projectSummary: coderInstructions.summary || '',
            projectRequirements: coderInstructions.requirements || [],
            coderInstructions: coderInstructions, // å‚³éå®Œæ•´çš„ coder instructions
            fileSpec: {
              path: file.path,
              language: file.language,
              description: file.description || '',
              requirements: file.requirements || []
            }
          };

          // Call worker agent (with built-in fallback)
          const result = await this.generateFileDetail(agent, file, context, requestId);
          
          // Check if result is valid
          if (!result || !result.success) {
            throw new Error(result?.error || 'Unknown error from generateFileDetail');
          }
          
          if (!result.content || result.content.trim() === '') {
            logger.warn(`âš  Empty content returned for ${file.path}, using skeleton`, requestId);
            // Use skeleton as fallback if content is empty
            return {
              path: file.path,
              content: skeletons[file.path] || `// Empty content for ${file.path}`,
              language: file.language,
              metadata: result.metadata || {},
              layer: layerIdx + 1
            };
          }
          
          // Log success (check if it was a fallback)
          const isFallback = result.metadata?.fallback === true;
          if (isFallback) {
            logger.info(`âœ“ Generated ${path.basename(file.path)} (via fallback)`, requestId, { 
              layer: layerIdx + 1,
              agent: agentName,
              size: result.content?.length || 0
            });
          } else {
          logger.info(`âœ… Generated ${path.basename(file.path)}`, requestId, { 
            layer: layerIdx + 1,
            agent: agentName,
            tokens: result.metadata?.tokens_used,
            size: result.content?.length || 0,
            hasContent: !!(result.content && result.content.trim())
          });
          }

          return {
            path: file.path,
            content: result.content,
            language: file.language,
            metadata: result.metadata || {},
            layer: layerIdx + 1
          };

        } catch (error) {
          // This catch should rarely be triggered now since generateFileDetail has fallback
          // But keep it as a safety net
          logger.warn(`âš  Fallback to skeleton for ${path.basename(file.path)}`, requestId, { 
            layer: layerIdx + 1,
            error: error.message 
          });
          
          // Use skeleton as final fallback
          return {
            path: file.path,
            content: skeletons[file.path] || `// Error generating ${file.path}: ${error.message}`,
            language: file.language,
            metadata: { fallback: true, error: error.message },
            layer: layerIdx + 1
          };
        }
      });

      // ç­‰å¾…ç•¶å‰å±¤çš„æ‰€æœ‰æª”æ¡ˆç”Ÿæˆå®Œæˆ
      const layerResults = await Promise.all(layerPromises);
      results.push(...layerResults);

      // å±¤èˆ‡å±¤ä¹‹é–“å»¶é²ï¼ˆæœ€å¾Œä¸€å±¤ä¸éœ€è¦å»¶é²ï¼‰
      if (!isLastLayer) {
        logger.info(`Layer ${layerIdx + 1} completed, waiting before next layer...`, requestId);
        await this.sleep(this.DETAIL_GENERATION_DELAY);
      }
    }

    const successful = results.filter(r => !r.error).length;
    const failed = results.filter(r => r.error).length;
    
    logger.info('Layered generation completed', requestId, { 
      totalLayers: groups.length,
      successful, 
      failed,
      successRate: `${(successful/files.length*100).toFixed(1)}%`
    });

    return results;
  }

  /**
   * Phase 3: çµ„è£æœ€çµ‚çµæœ
   */
  async assemble(detailedFiles, skeletons, requestId, payload = null) {
    const successful = detailedFiles.filter(f => !f.error);
    const failed = detailedFiles.filter(f => f.error);
    
    const notes = [
      `Generated ${detailedFiles.length} files`,
      `âœ… Successful: ${successful.length}`,
      failed.length > 0 ? `âŒ Failed: ${failed.length}` : null,
      'All files processed via Coordinator'
    ].filter(Boolean);

    // æ·»åŠ å¤±æ•—çš„æª”æ¡ˆè©³æƒ…
    if (failed.length > 0) {
      notes.push('Failed files:');
      failed.forEach(f => {
        notes.push(`  - ${f.path}: ${f.error}`);
      });
    }

    // æ”¶é›†æ‰€æœ‰æª”æ¡ˆï¼ˆåŒ…æ‹¬ç”Ÿæˆçš„å’Œ setup æª”æ¡ˆï¼‰
    let allFiles = detailedFiles.map(f => ({
      path: f.path,
      template: f.content,
      language: f.language
    }));

    // å¦‚æœ payload æœ‰ setup æ¬„ä½ï¼Œè‡ªå‹•ç”Ÿæˆ setup æª”æ¡ˆ
    if (payload && payload.coder_instructions && payload.coder_instructions.setup) {
      const setupFiles = this.generateSetupFiles(payload.coder_instructions.setup);
      allFiles = allFiles.concat(setupFiles);
      notes.push(`ğŸ“¦ Generated ${setupFiles.length} setup files (package.json, README.md, etc.)`);
    }

    return {
      request_id: `coder-${Date.now()}`,
      received_at: new Date().toISOString(),
      suggested_action: 'generate_files',
      notes: notes,
      files: allFiles,
      metadata: {
        total_files: allFiles.length,
        successful_files: successful.length,
        failed_files: failed.length,
        coordinator_version: '1.0.0',
        generation_method: 'skeleton_then_details'
      }
    };
  }

  /**
   * æ ¹æ“š setup é…ç½®ç”Ÿæˆ setup æª”æ¡ˆ
   */
  generateSetupFiles(setup) {
    const setupFiles = [];

    // 1. ç”Ÿæˆ package.jsonï¼ˆå¦‚æœæœ‰ npm ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.npm && setup.dependencies.npm.length > 0) {
      const packageJson = {
        name: "generated-project",
        version: "1.0.0",
        description: "Auto-generated project",
        scripts: {},
        dependencies: {}
      };

      // è§£æä¾è³´ï¼ˆæ”¯æ´ "express@4.18.0" å’Œ "express" æ ¼å¼ï¼‰
      setup.dependencies.npm.forEach(dep => {
        const [name, version] = dep.includes('@') && !dep.startsWith('@') 
          ? dep.split('@') 
          : [dep, 'latest'];
        packageJson.dependencies[name] = version;
      });

      // æ·»åŠ å•Ÿå‹•è…³æœ¬
      if (setup.startCommands && setup.startCommands.frontend) {
        packageJson.scripts.start = setup.startCommands.frontend;
      }
      if (setup.startCommands && setup.startCommands.backend) {
        packageJson.scripts.server = setup.startCommands.backend;
      }

      setupFiles.push({
        path: 'package.json',
        template: JSON.stringify(packageJson, null, 2),
        language: 'json'
      });
    }

    // 2. ç”Ÿæˆ requirements.txtï¼ˆå¦‚æœæœ‰ python ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.python && setup.dependencies.python.length > 0) {
      const requirementsTxt = setup.dependencies.python.join('\n');
      setupFiles.push({
        path: 'requirements.txt',
        template: requirementsTxt,
        language: 'text'
      });
    }

    // 3. ç”Ÿæˆ pom.xmlï¼ˆå¦‚æœæœ‰ maven ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.maven && setup.dependencies.maven.length > 0) {
      const pomXml = `<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <groupId>com.example</groupId>
    <artifactId>generated-project</artifactId>
    <version>1.0.0</version>
    
    <properties>
        <maven.compiler.source>${setup.javaVersion || '17'}</maven.compiler.source>
        <maven.compiler.target>${setup.javaVersion || '17'}</maven.compiler.target>
    </properties>
    
    <dependencies>
${setup.dependencies.maven.map(dep => {
  const [groupArtifact, version] = dep.split(':');
  const [groupId, artifactId] = groupArtifact.split('/');
  return `        <dependency>
            <groupId>${groupId}</groupId>
            <artifactId>${artifactId}</artifactId>
            <version>${version}</version>
        </dependency>`;
}).join('\n')}
    </dependencies>
</project>`;
      setupFiles.push({
        path: 'pom.xml',
        template: pomXml,
        language: 'xml'
      });
    }

    // 4. ç”Ÿæˆ go.modï¼ˆå¦‚æœæœ‰ go ä¾è³´ï¼‰
    if (setup.dependencies && setup.dependencies.go && setup.dependencies.go.length > 0) {
      const goMod = `module generated-project

go ${setup.goVersion || '1.21'}

require (
${setup.dependencies.go.map(dep => `\t${dep}`).join('\n')}
)`;
      setupFiles.push({
        path: 'go.mod',
        template: goMod,
        language: 'text'
      });
    }

    // 5. ç”Ÿæˆ .env.exampleï¼ˆå¦‚æœæœ‰ç’°å¢ƒè®Šæ•¸ï¼‰
    if (setup.environmentVariables && Object.keys(setup.environmentVariables).length > 0) {
      const envExample = Object.entries(setup.environmentVariables)
        .map(([key, value]) => `${key}=${value}`)
        .join('\n');
      setupFiles.push({
        path: '.env.example',
        template: envExample,
        language: 'text'
      });
    }

    // 6. ç”Ÿæˆ README.md
    let readmeContent = '# Generated Project\n\n';
    
    if (setup.instructions) {
      readmeContent += `## Setup Instructions\n\n${setup.instructions}\n\n`;
    }

    if (setup.dependencies) {
      readmeContent += '## Dependencies\n\n';
      if (setup.dependencies.npm) {
        readmeContent += `**Node.js**: ${setup.nodeVersion || 'latest'}\n`;
        readmeContent += '```bash\nnpm install\n```\n\n';
      }
      if (setup.dependencies.python) {
        readmeContent += `**Python**: ${setup.pythonVersion || '3.8+'}\n`;
        readmeContent += '```bash\npip install -r requirements.txt\n```\n\n';
      }
      if (setup.dependencies.maven) {
        readmeContent += `**Java**: ${setup.javaVersion || '17+'}\n`;
        readmeContent += '```bash\nmvn clean install\n```\n\n';
      }
      if (setup.dependencies.go) {
        readmeContent += `**Go**: ${setup.goVersion || '1.21+'}\n`;
        readmeContent += '```bash\ngo mod download\n```\n\n';
      }
    }

    if (setup.startCommands) {
      readmeContent += '## Running the Project\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        readmeContent += `**${name}**:\n\`\`\`bash\n${command}\n\`\`\`\n\n`;
      });
    }

    if (setup.environmentVariables) {
      readmeContent += '## Environment Variables\n\n';
      readmeContent += 'Copy `.env.example` to `.env` and fill in the values:\n\n';
      Object.keys(setup.environmentVariables).forEach(key => {
        readmeContent += `- \`${key}\`\n`;
      });
    }

    setupFiles.push({
      path: 'README.md',
      template: readmeContent,
      language: 'markdown'
    });

    // 7. ç”Ÿæˆå•Ÿå‹•è…³æœ¬ start.sh / start.batï¼ˆå¦‚æœæœ‰ startCommandsï¼‰
    if (setup.startCommands) {
      // start.sh (Linux/Mac)
      let startSh = '#!/bin/bash\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        startSh += `echo "Starting ${name}..."\n${command} &\n\n`;
      });
      startSh += 'wait\n';
      setupFiles.push({
        path: 'start.sh',
        template: startSh,
        language: 'shell'
      });

      // start.bat (Windows)
      let startBat = '@echo off\n\n';
      Object.entries(setup.startCommands).forEach(([name, command]) => {
        startBat += `echo Starting ${name}...\nstart /B ${command}\n\n`;
      });
      setupFiles.push({
        path: 'start.bat',
        template: startBat,
        language: 'batch'
      });
    }

    return setupFiles;
  }

  // ===== Helper Methods =====

  /**
   * æŒ‰èªè¨€åˆ†çµ„æª”æ¡ˆ
   */
  groupFilesByLanguage(files) {
    const groups = {};
    
    files.forEach(file => {
      const lang = file.language || 'other';
      if (!groups[lang]) groups[lang] = [];
      groups[lang].push(file);
    });

    return groups;
  }

  /**
   * æ ¹æ“šæª”æ¡ˆè·¯å¾‘é¸æ“‡ worker agent
   */
  selectAgent(filePath) {
    const ext = path.extname(filePath).toLowerCase();
    
    for (const [name, worker] of Object.entries(this.workers)) {
      if (worker.exts.includes(ext)) {
        return worker;
      }
    }
    
    // é è¨­ä½¿ç”¨ system agent
    return this.workers.system;
  }

  /**
   * å–å¾— agent åç¨±
   */
  getAgentName(agent) {
    for (const [name, worker] of Object.entries(this.workers)) {
      if (worker === agent) return name;
    }
    return 'unknown';
  }

  /**
   * å‘¼å«é›²ç«¯ API
   */
  async callCloudAPI(payload, requestId) {
    // Phase 1 éª¨æ¶ç”Ÿæˆï¼šä½¿ç”¨é›²ç«¯ API ç”Ÿæˆçµæ§‹åŒ–éª¨æ¶
    if (payload.task === 'generate_skeletons') {
      logger.info('Using Cloud API for skeleton generation', requestId);
      
      // å¦‚æœæ²’æœ‰é…ç½® APIï¼Œfallback åˆ° mock
      if (!this.CLOUD_API_ENDPOINT || !this.CLOUD_API_KEY) {
        logger.warn('Cloud API not configured, using mock for skeletons', requestId);
        return this.mockCloudAPI(payload, requestId);
      }
      
      // å‘¼å«é›²ç«¯ API ç”Ÿæˆéª¨æ¶
      try {
        return await this.generateSkeletonsViaAPI(payload, requestId);
      } catch (error) {
        logger.error('Skeleton API call failed, falling back to mock', requestId, { error: error.message });
        return this.mockCloudAPI(payload, requestId);
      }
    }
    
    // Phase 2 ç´°ç¯€ç”Ÿæˆï¼šæ ¹æ“šé…ç½®æ±ºå®šä½¿ç”¨ mock é‚„æ˜¯ Worker Agents
    if (this.USE_MOCK_API) {
      return this.mockCloudAPI(payload, requestId);
    }

    // çœŸå¯¦ API å‘¼å«ï¼ˆç›®å‰ä¸æœƒåˆ°é”é€™è£¡ï¼Œå› ç‚º Phase 2 ç”¨ Worker Agentsï¼‰
    try {
      const response = await fetch(this.CLOUD_API_ENDPOINT, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.CLOUD_API_KEY}`,
          'X-Request-ID': requestId || 'no-request-id'
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Cloud API error: ${response.status} ${response.statusText} - ${errorText}`);
      }

      return await response.json();
      
    } catch (error) {
      logger.error('Cloud API call failed', requestId, { error: error.message });
      throw error;
    }
  }

  /**
   * ä½¿ç”¨ Cloud API ç”Ÿæˆéª¨æ¶
   */
  async generateSkeletonsViaAPI(payload, requestId) {
    logger.info('Calling Cloud API to generate skeletons', requestId, { 
      fileCount: payload.files.length 
    });

    // å»ºæ§‹ promptï¼šè¦æ±‚ LLM ç”Ÿæˆæ‰€æœ‰æª”æ¡ˆçš„çµæ§‹åŒ–éª¨æ¶
    // å¦‚æœ payload åŒ…å« contractsï¼Œå‰‡å¼·åˆ¶éµå¾ªï¼›å¦å‰‡ç”± LLM æ¨æ–·ä¸€è‡´æ€§
    const hasContracts = payload.contracts && Object.keys(payload.contracts).length > 0;
    
    const systemPrompt = `You are an expert code architect. Generate structural skeletons for application files (web, mobile, backend, CLI, etc.).

Your task:
1. Generate file structure with:
   - Import statements
   - Function/class signatures
   - Type definitions
   - Key comments describing responsibilities
2. DO NOT implement logic - only structure
3. CRITICAL CONSISTENCY RULES (apply to ALL file types):
   - Cross-file references MUST be exact (HTML IDs â†’ CSS selectors â†’ JS querySelector)
   - Data attributes: HTML data-* values MUST match JS event handler checks exactly
   - Function names: HTML onclick/event references â†’ JS function names must match
   - File paths: <link>/<script> src â†’ actual file names must match
   - Variable naming: Shared concepts across files use consistent naming (camelCase in JS, snake_case in Python)
${hasContracts ? `
4. CONTRACT ENFORCEMENT (HIGHEST PRIORITY):
   The payload includes explicit contracts for cross-file communication.
   You MUST follow these contracts EXACTLY - no interpretation, no assumptions.
   
   For API contracts:
   - Include skeleton comments with EXACT request/response structure from contract
   - Frontend and backend MUST use IDENTICAL field names
   - Example: 
     /* API Contract: POST /api/orders
      * Request: { customer: {name: string, email: string}, items: [{productId: string, quantity: number}] }
      * Response: { orderId: string, total: number, status: string }
      */
   - Python: Use TypedDict/Pydantic models matching contract EXACTLY
   - JavaScript: Use JSDoc @typedef matching contract EXACTLY
   
   For module contracts:
   - Export functions MUST match signatures in contract
   - Import statements MUST reference correct module names
   
   For event contracts:
   - Event names and payload structures MUST match contract
   - dispatchEvent() and addEventListener() must use exact event names
   
   For storage contracts:
   - localStorage/sessionStorage keys MUST match contract
   - Data structures stored MUST match contract schema
   
   For class contracts:
   - Class fields and methods MUST match contract definition
   - Serialization methods (to_dict, toJSON) MUST follow contract structure
` : `
4. INFERRED CONSISTENCY (when no explicit contracts provided):
   - For API endpoints: Infer minimal REST-style payloads from descriptions
   - Document inferred structure in skeleton comments
   - Use standard conventions (e.g., {id, name, ...} for entities)
   - Keep structures simple and predictable
`}
5. Language-specific best practices:
   - HTML: Semantic tags, accessibility attributes
   - CSS: BEM naming, mobile-first, CSS Grid/Flexbox
   - JavaScript: ES6+, async/await, error handling
   - Python: Type hints, docstrings, PEP 8
   - Java: Interfaces, generics, JavaDoc
6. JSON OUTPUT REQUIREMENTS:
   - Output MUST be valid JSON array: [{"path": "...", "content": "..."}, ...]
   - For multi-line content, use actual newlines inside the JSON string (this is valid JSON)
   - You may wrap the JSON in markdown code block (triple backticks + json) for clarity
   - The content field should contain the code as-is without extra escaping
`;

    // æå–ç”¨æˆ¶éœ€æ±‚ï¼ˆå¾ coderInstructions æˆ– payloadï¼‰
    const coderInstructions = this.currentCoderInstructions || {};
    const userRequirement = payload.summary || payload.requirements || coderInstructions.summary || coderInstructions.requirements || '';
    const projectRequirements = Array.isArray(payload.requirements) ? payload.requirements : (payload.requirements ? [payload.requirements] : []);
    
    let userPrompt = `Generate skeletons for these files:

${userRequirement ? `=== USER REQUIREMENT ===
${userRequirement}

` : ''}${projectRequirements.length > 0 ? `=== PROJECT REQUIREMENTS ===
${projectRequirements.join('\n')}

` : ''}Files to generate:
${payload.files.map((f, i) => `${i + 1}. ${f.path} (${f.type}): ${f.description || 'No description'}${f.requirements && f.requirements.length > 0 ? `\n   Requirements: ${Array.isArray(f.requirements) ? f.requirements.join(', ') : f.requirements}` : ''}`).join('\n')}
`;

    // å¦‚æœæœ‰ contractsï¼Œé™„åŠ åˆ° prompt
    if (hasContracts) {
      userPrompt += `\n\n=== CONTRACTS (MUST FOLLOW EXACTLY) ===\n`;
      
      if (payload.contracts.api && payload.contracts.api.length > 0) {
        userPrompt += `\nAPI Endpoints:\n`;
        payload.contracts.api.forEach((api, i) => {
          userPrompt += `${i + 1}. ${api.endpoint} - ${api.description}\n`;
          userPrompt += `   Request: ${JSON.stringify(api.request, null, 2)}\n`;
          userPrompt += `   Response: ${JSON.stringify(api.response, null, 2)}\n`;
          userPrompt += `   Producers: ${api.producers.join(', ')}\n`;
          userPrompt += `   Consumers: ${api.consumers.join(', ')}\n\n`;
        });
      }
      
      if (payload.contracts.modules && payload.contracts.modules.length > 0) {
        userPrompt += `\nModules:\n`;
        payload.contracts.modules.forEach((mod, i) => {
          userPrompt += `${i + 1}. ${mod.name} (${mod.file})\n`;
          userPrompt += `   Exports: ${JSON.stringify(mod.exports, null, 2)}\n`;
          userPrompt += `   Importers: ${mod.importers.join(', ')}\n\n`;
        });
      }
      
      if (payload.contracts.events && payload.contracts.events.length > 0) {
        userPrompt += `\nCustom Events:\n`;
        payload.contracts.events.forEach((evt, i) => {
          userPrompt += `${i + 1}. ${evt.name} - ${evt.description}\n`;
          userPrompt += `   Payload: ${JSON.stringify(evt.payload, null, 2)}\n`;
          userPrompt += `   Emitters: ${evt.emitters.join(', ')}\n`;
          userPrompt += `   Listeners: ${evt.listeners.join(', ')}\n\n`;
        });
      }
      
      if (payload.contracts.storage && payload.contracts.storage.length > 0) {
        userPrompt += `\nStorage:\n`;
        payload.contracts.storage.forEach((store, i) => {
          userPrompt += `${i + 1}. ${store.key} (${store.type}) - ${store.description}\n`;
          userPrompt += `   Schema: ${JSON.stringify(store.schema, null, 2)}\n`;
          userPrompt += `   Writers: ${store.writers.join(', ')}\n`;
          userPrompt += `   Readers: ${store.readers.join(', ')}\n\n`;
        });
      }
      
      if (payload.contracts.classes && payload.contracts.classes.length > 0) {
        userPrompt += `\nShared Classes:\n`;
        payload.contracts.classes.forEach((cls, i) => {
          userPrompt += `${i + 1}. ${cls.name} (${cls.file})\n`;
          userPrompt += `   Fields: ${JSON.stringify(cls.fields, null, 2)}\n`;
          if (cls.methods) userPrompt += `   Methods: ${JSON.stringify(cls.methods, null, 2)}\n`;
          userPrompt += `   Consumers: ${cls.consumers.join(', ')}\n\n`;
        });
      }
      
      userPrompt += `\n=== END CONTRACTS ===\n`;
    }

    // ç‚º HTML æª”æ¡ˆè¨ˆç®—ç›¸å°è·¯å¾‘
    const htmlFiles = payload.files.filter(f => f.path.endsWith('.html') || f.path.endsWith('.htm'));
    const cssFiles = payload.files.filter(f => f.path.endsWith('.css'));
    const jsFiles = payload.files.filter(f => f.path.endsWith('.js') || f.path.endsWith('.mjs') || f.path.endsWith('.cjs'));
    
    if (htmlFiles.length > 0 && (cssFiles.length > 0 || jsFiles.length > 0)) {
      userPrompt += `\n=== FILE PATH RELATIONSHIPS ===\n`;
      htmlFiles.forEach(htmlFile => {
        const htmlDir = path.dirname(htmlFile.path);
        userPrompt += `\nFor HTML file: ${htmlFile.path}\n`;
        if (cssFiles.length > 0) {
          userPrompt += `  CSS files (use relative paths from HTML directory):\n`;
          cssFiles.forEach(cssFile => {
            const relPath = path.relative(htmlDir, cssFile.path).replace(/\\/g, '/');
            userPrompt += `    - ${cssFile.path} â†’ use "${relPath}" in <link> tag\n`;
          });
        }
        if (jsFiles.length > 0) {
          userPrompt += `  JS files (use relative paths from HTML directory):\n`;
          jsFiles.forEach(jsFile => {
            const relPath = path.relative(htmlDir, jsFile.path).replace(/\\/g, '/');
            userPrompt += `    - ${jsFile.path} â†’ use "${relPath}" in <script> tag\n`;
          });
        }
      });
      userPrompt += `\nCRITICAL: HTML files MUST use the exact relative paths shown above.\n`;
      userPrompt += `Do NOT invent paths like "styles/main.css" or "scripts/main.js".\n`;
      userPrompt += `CRITICAL: Match the EXACT filename from the relative path (e.g., if path is "index.js", use src="index.js", NOT "app.js" or "main.js").\n`;
      userPrompt += `=== END FILE PATH RELATIONSHIPS ===\n\n`;
    }

    userPrompt += `
Generate structural skeletons following language conventions:
- HTML: DOCTYPE, head, body structure, script/link tags with CORRECT relative file paths (see above)
- CSS: Selectors matching HTML classes/IDs
- JavaScript: Function signatures, class definitions, imports, event listeners
- Python: Class/function definitions, imports, type hints, route handlers
- Java: Package declarations, imports, class/interface definitions

${hasContracts ? 
'IMPORTANT: Follow the contracts EXACTLY. Every field name, type, and structure must match.' :
'CONSISTENCY CHECK: Infer consistent structures across files. Every frontend API call should have a backend route.'}

IMPORTANT: Your response must be VALID JSON that can be parsed by JSON.parse().
Ensure all special characters are properly escaped according to JSON specification.
Do not include any text before or after the JSON array.

Return ONLY the JSON array, no markdown or explanation.`;

    // å„ªå…ˆå˜—è©¦ Geminiï¼Œå¤±æ•—æ™‚åˆ‡æ›åˆ° OpenAIï¼ˆä¸€æ¬¡åªä½¿ç”¨ä¸€å€‹ APIï¼‰
    const apiProviders = [];
    
    // å„ªå…ˆæ·»åŠ  Gemini
    if (this.GEMINI_API_KEY) {
      apiProviders.push({
        name: 'Gemini',
        endpoint: `${this.GEMINI_API_ENDPOINT}/models/${this.GEMINI_MODEL}:generateContent`,
        key: this.GEMINI_API_KEY,
        isGemini: true
      });
    }
    
    // ç„¶å¾Œæ·»åŠ  OpenAIï¼ˆå‚™ç”¨ï¼‰
    if (this.OPENAI_API_ENDPOINT && this.OPENAI_API_KEY) {
      apiProviders.push({
        name: 'OpenAI',
        endpoint: this.OPENAI_API_ENDPOINT,
        key: this.OPENAI_API_KEY,
        isGemini: false
      });
    }
    
    if (apiProviders.length === 0) {
      throw new Error('No API providers configured (neither Gemini nor OpenAI)');
    }
    
    let lastError = null;
    
    // ä¾æ¬¡å˜—è©¦æ¯å€‹ API æä¾›è€…ï¼ˆå„ªå…ˆ Geminiï¼‰
    for (const provider of apiProviders) {
      try {
        logger.info(`Trying ${provider.name} API for skeleton generation`, requestId);
        
        let requestBody, headers, apiUrl, response, result, generatedText;
        
        if (provider.isGemini) {
          // Gemini API æ ¼å¼
          requestBody = {
            contents: [{
              parts: [{
                text: `${systemPrompt}\n\n${userPrompt}`
              }]
            }],
            generationConfig: {
              temperature: 0.3,
              maxOutputTokens: 16384
            }
          };
          
          headers = {
            'Content-Type': 'application/json'
          };
          
          // Gemini ä½¿ç”¨ query parameter èªè­‰
          apiUrl = `${provider.endpoint}?key=${provider.key}`;
          
          response = await fetch(apiUrl, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify(requestBody)
          });

          if (!response.ok) {
            const errorText = await response.text();
            const statusCode = response.status;
            const errorCode = JSON.parse(errorText || '{}')?.error?.code;
            
            // å¦‚æœæ˜¯é…é¡éŒ¯èª¤æˆ–èªè­‰éŒ¯èª¤ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            if (statusCode === 429 || errorCode === 'insufficient_quota' || statusCode === 401 || statusCode === 403) {
              logger.warn(`${provider.name} API failed (${statusCode || errorCode}), switching to next provider...`, requestId);
              lastError = new Error(`${provider.name} API error: ${statusCode} - ${errorText}`);
              continue; // å˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            }
            throw new Error(`Gemini API error: ${statusCode} - ${errorText}`);
          }

          result = await response.json();
          generatedText = result.candidates[0].content.parts[0].text;
          
        } else {
          // OpenAI API æ ¼å¼
          requestBody = {
            model: 'gpt-4',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: userPrompt }
            ],
            temperature: 0.3,
            max_tokens: 4000
          };
          
          headers = {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${provider.key}`
          };
          
          response = await fetch(provider.endpoint, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify(requestBody)
          });

          if (!response.ok) {
            const errorText = await response.text();
            const statusCode = response.status;
            const errorCode = JSON.parse(errorText || '{}')?.error?.code;
            
            // å¦‚æœæ˜¯é…é¡éŒ¯èª¤æˆ–èªè­‰éŒ¯èª¤ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            if (statusCode === 429 || errorCode === 'insufficient_quota' || statusCode === 401 || statusCode === 403) {
              logger.warn(`${provider.name} API failed (${statusCode || errorCode}), switching to next provider...`, requestId);
              lastError = new Error(`OpenAI API error: ${statusCode} - ${errorText}`);
              continue; // å˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            }
            throw new Error(`OpenAI API error: ${statusCode} - ${errorText}`);
          }

          result = await response.json();
          generatedText = result.choices[0].message.content;
        }
        
        logger.info('Raw API response received', requestId, {
          provider: provider.name,
          textLength: generatedText.length,
          preview: generatedText.substring(0, 200)
        });
        
        // ç§»é™¤å¯èƒ½çš„ markdown code block åŒ…è£
        let cleanedText = generatedText.trim();
        if (cleanedText.startsWith('```json')) {
          cleanedText = cleanedText.replace(/^```json\s*\n/, '').replace(/\n```\s*$/, '');
        } else if (cleanedText.startsWith('```')) {
          cleanedText = cleanedText.replace(/^```\s*\n/, '').replace(/\n```\s*$/, '');
        }
        
        // è§£æ JSON
        const jsonMatch = cleanedText.match(/\[[\s\S]*\]/);
        if (!jsonMatch) {
          logger.error('No JSON array found in response', requestId, {
            fullText: cleanedText.substring(0, 2000)
          });
          throw new Error('API response does not contain valid JSON array');
        }
        
        let skeletons;
        try {
          skeletons = JSON.parse(jsonMatch[0]);
        } catch (parseError) {
          logger.error('JSON parse failed', requestId, {
            error: parseError.message,
            jsonPreview: jsonMatch[0].substring(0, 1000),
            jsonLength: jsonMatch[0].length
          });
          
          // å˜—è©¦ä¿®å¾©å¸¸è¦‹çš„è½‰ç¾©å•é¡Œ
          try {
            let fixedJson = jsonMatch[0]
              .replace(/\\\\\\\\/g, '\\')
              .replace(/\\\\\"/g, '"')
              .replace(/\\\\n/g, '\\n');
            
            skeletons = JSON.parse(fixedJson);
            logger.info('JSON parse succeeded after fixing escaping', requestId);
          } catch (fixError) {
            logger.error('JSON fix attempt also failed', requestId, {
              fixError: fixError.message
            });
            throw new Error(`Failed to parse JSON: ${parseError.message}`);
          }
        }
        
        logger.info('Skeleton generation via API completed', requestId, {
          provider: provider.name,
          fileCount: skeletons.length,
          tokensUsed: provider.isGemini ? (result.usageMetadata?.totalTokenCount || 0) : (result.usage?.total_tokens || 0)
        });
        
        return { skeletons };
        
      } catch (error) {
        lastError = error;
        // å¦‚æœé‚„æœ‰å…¶ä»–æä¾›è€…å¯ä»¥å˜—è©¦ï¼Œç¹¼çºŒ
        if (apiProviders.indexOf(provider) < apiProviders.length - 1) {
          logger.warn(`${provider.name} API request failed, trying next provider...`, requestId, {
            error: error.message
          });
          continue;
        }
        // å¦‚æœæ˜¯æœ€å¾Œä¸€å€‹æä¾›è€…ï¼Œæ‹‹å‡ºéŒ¯èª¤
        logger.error('Failed to generate skeletons via API', requestId, { 
          error: error.message,
          triedProviders: apiProviders.map(p => p.name).join(', ')
        });
        throw error;
      }
    }
    
    // æ‰€æœ‰æä¾›è€…éƒ½å¤±æ•—äº†
    throw lastError || new Error('All API providers failed');
  }

  /**
   * ä½¿ç”¨ Cloud API ç”Ÿæˆæª”æ¡ˆç´°ç¯€
   */
  async generateDetailsViaCloudAPI(payload, requestId) {
    logger.info('Calling Cloud API to generate file details', requestId, { 
      file: payload.fileSpec?.path 
    });

    const fileSpec = payload.fileSpec || {};
    const skeleton = payload.skeleton || '';
    const context = payload.context || {};
    
    const systemPrompt = `You are an expert software developer. Generate complete, production-ready code implementations.

Your task:
1. Take the provided skeleton code and expand it into a complete, working implementation
2. Include all necessary functionality, error handling, and best practices
3. Ensure code is well-structured, readable, and follows language conventions
4. Add appropriate comments for complex logic
5. Ensure consistency with related files (if provided in context)

Requirements:
- Generate COMPLETE, WORKING code (not just placeholders)
- Include proper error handling
- Follow best practices for the language
- Maintain consistency with skeleton structure
- If context includes completed files, ensure compatibility`;

    // æ§‹å»ºåŒ…å«ç”¨æˆ¶éœ€æ±‚çš„å®Œæ•´ prompt
    const userRequirement = context.userRequirement || context.projectSummary || '';
    const projectRequirements = context.projectRequirements || [];
    
    const userPrompt = `Generate complete implementation for: ${fileSpec.path}

${userRequirement ? `=== USER REQUIREMENT ===
${userRequirement}

` : ''}${projectRequirements.length > 0 ? `=== PROJECT REQUIREMENTS ===
${Array.isArray(projectRequirements) ? projectRequirements.join('\n') : projectRequirements}

` : ''}File Type: ${fileSpec.language || 'unknown'}
Description: ${fileSpec.description || 'No description'}
${fileSpec.requirements && fileSpec.requirements.length > 0 ? `
File-Specific Requirements:
${Array.isArray(fileSpec.requirements) ? fileSpec.requirements.join('\n') : fileSpec.requirements}
` : ''}

Skeleton Code:
\`\`\`${fileSpec.language || 'text'}
${skeleton}
\`\`\`

${context.completedFiles && context.completedFiles.length > 0 ? `
Related Files (for reference):
${context.completedFiles.map(f => `- ${f.path} (${f.language})`).join('\n')}
` : ''}

${context.dependencies && context.dependencies.length > 0 ? `
Dependencies:
${context.dependencies.map(d => `- ${d.path}`).join('\n')}
` : ''}

Generate the complete implementation now. 

CRITICAL REQUIREMENTS:
- The code MUST implement the user's requirement: "${userRequirement || 'see description above'}"
- Return ONLY the code content, no explanations, no apologies, no markdown formatting
- For JSON files: Return valid JSON only, no text before or after
- For JavaScript files: Return complete, working code that fulfills the user's requirement
- For config files: Return appropriate configuration based on file path (backend config should export module.exports, frontend config should use window.APP_CONFIG)
- If the skeleton is empty or unclear, infer reasonable defaults based on the user requirement and file path/description
- The implementation should be specific to the user's needs, not a generic template

DO NOT include phrases like "Apologies", "I'm sorry", "Here's the code", etc. Just return the code directly.`;

    // å„ªå…ˆå˜—è©¦ Geminiï¼Œå¤±æ•—æ™‚åˆ‡æ›åˆ° OpenAIï¼ˆä¸€æ¬¡åªä½¿ç”¨ä¸€å€‹ APIï¼‰
    const apiProviders = [];
    
    // å„ªå…ˆæ·»åŠ  Gemini
    if (this.GEMINI_API_KEY) {
      apiProviders.push({
        name: 'Gemini',
        endpoint: `${this.GEMINI_API_ENDPOINT}/models/${this.GEMINI_MODEL}:generateContent`,
        key: this.GEMINI_API_KEY,
        isGemini: true
      });
    }
    
    // ç„¶å¾Œæ·»åŠ  OpenAIï¼ˆå‚™ç”¨ï¼‰
    if (this.OPENAI_API_ENDPOINT && this.OPENAI_API_KEY) {
      apiProviders.push({
        name: 'OpenAI',
        endpoint: this.OPENAI_API_ENDPOINT,
        key: this.OPENAI_API_KEY,
        isGemini: false
      });
    }
    
    if (apiProviders.length === 0) {
      throw new Error('No API providers configured (neither Gemini nor OpenAI)');
    }
    
    let lastError = null;
    
    // ä¾æ¬¡å˜—è©¦æ¯å€‹ API æä¾›è€…ï¼ˆå„ªå…ˆ Geminiï¼‰
    for (const provider of apiProviders) {
      try {
        logger.info(`Trying ${provider.name} API for detail generation`, requestId, {
          file: fileSpec.path
        });
        
        let requestBody, headers, apiUrl, response, result, generatedText;
        
        if (provider.isGemini) {
          // Gemini API æ ¼å¼
          requestBody = {
            contents: [{
              parts: [{
                text: `${systemPrompt}\n\n${userPrompt}`
              }]
            }],
            generationConfig: {
              temperature: 0.5,
              maxOutputTokens: 8192
            }
          };
          
          headers = {
            'Content-Type': 'application/json'
          };
          
          apiUrl = `${provider.endpoint}?key=${provider.key}`;
          
          response = await fetch(apiUrl, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify(requestBody)
          });

          if (!response.ok) {
            const errorText = await response.text();
            const statusCode = response.status;
            const errorCode = JSON.parse(errorText || '{}')?.error?.code;
            
            // å¦‚æœæ˜¯é…é¡éŒ¯èª¤æˆ–èªè­‰éŒ¯èª¤ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            if (statusCode === 429 || errorCode === 'insufficient_quota' || statusCode === 401 || statusCode === 403) {
              logger.warn(`${provider.name} API failed (${statusCode || errorCode}), switching to next provider...`, requestId, {
                file: fileSpec.path
              });
              lastError = new Error(`Gemini API error: ${statusCode} - ${errorText}`);
              continue; // å˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            }
            throw new Error(`Gemini API error: ${statusCode} - ${errorText}`);
          }

          result = await response.json();
          generatedText = result.candidates[0].content.parts[0].text;
          
        } else {
          // OpenAI API æ ¼å¼
          requestBody = {
            model: 'gpt-4',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: userPrompt }
            ],
            temperature: 0.5,
            max_tokens: 4000
          };
          
          headers = {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${provider.key}`
          };
          
          response = await fetch(provider.endpoint, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify(requestBody)
          });

          if (!response.ok) {
            const errorText = await response.text();
            const statusCode = response.status;
            const errorCode = JSON.parse(errorText || '{}')?.error?.code;
            
            // å¦‚æœæ˜¯é…é¡éŒ¯èª¤æˆ–èªè­‰éŒ¯èª¤ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            if (statusCode === 429 || errorCode === 'insufficient_quota' || statusCode === 401 || statusCode === 403) {
              logger.warn(`${provider.name} API failed (${statusCode || errorCode}), switching to next provider...`, requestId, {
                file: fileSpec.path
              });
              lastError = new Error(`OpenAI API error: ${statusCode} - ${errorText}`);
              continue; // å˜—è©¦ä¸‹ä¸€å€‹æä¾›è€…
            }
            throw new Error(`OpenAI API error: ${statusCode} - ${errorText}`);
          }

          result = await response.json();
          generatedText = result.choices[0].message.content;
        }
        
        // ç§»é™¤å¯èƒ½çš„ markdown code block åŒ…è£å’ŒéŒ¯èª¤è¨Šæ¯
        let content = generatedText.trim();
        
        // æª¢æŸ¥æ˜¯å¦åŒ…å«éŒ¯èª¤è¨Šæ¯ï¼ˆAPI å¯èƒ½è¿”å›éŒ¯èª¤è€Œä¸æ˜¯ä»£ç¢¼ï¼‰
        if (content.toLowerCase().includes('apologies') || 
            content.toLowerCase().includes('i\'m sorry') ||
            content.toLowerCase().includes('i cannot') ||
            content.toLowerCase().includes('unclear') ||
            content.toLowerCase().includes('confusion') ||
            content.toLowerCase().includes('not clear')) {
          logger.warn('Cloud API returned error message instead of code, using skeleton', requestId, {
            file: fileSpec.path,
            preview: content.substring(0, 200)
          });
          // ä½¿ç”¨éª¨æ¶ä½œç‚º fallback
          content = skeleton || '';
        }
        
        // ç§»é™¤ markdown code block åŒ…è£
        if (content.startsWith('```')) {
          content = content.replace(/^```[\w]*\s*\n/, '').replace(/\n```\s*$/, '');
        }
        
        // ç§»é™¤å¸¸è¦‹çš„å‰ç¶´æ–‡å­—
        content = content.replace(/^(here's|here is|the code|code:|implementation:)\s*/i, '');
        
        logger.info('Detail generation via Cloud API completed', requestId, {
          provider: provider.name,
          file: fileSpec.path,
          contentLength: content.length,
          tokensUsed: provider.isGemini ? (result.usageMetadata?.totalTokenCount || 0) : (result.usage?.total_tokens || 0)
        });
        
        return {
          content: content,
          metadata: {
            tokens_used: provider.isGemini ? (result.usageMetadata?.totalTokenCount || 0) : (result.usage?.total_tokens || 0),
            model: provider.isGemini ? 'gemini-2.5-flash' : 'gpt-4',
            method: 'cloud_api'
          }
        };
        
      } catch (error) {
        lastError = error;
        // å¦‚æœé‚„æœ‰å…¶ä»–æä¾›è€…å¯ä»¥å˜—è©¦ï¼Œç¹¼çºŒ
        if (apiProviders.indexOf(provider) < apiProviders.length - 1) {
          logger.warn(`${provider.name} API request failed, trying next provider...`, requestId, {
            file: fileSpec.path,
            error: error.message
          });
          continue;
        }
        // å¦‚æœæ˜¯æœ€å¾Œä¸€å€‹æä¾›è€…ï¼Œæ‹‹å‡ºéŒ¯èª¤
        logger.error('Failed to generate details via Cloud API', requestId, {
          error: error.message,
          file: fileSpec.path,
          triedProviders: apiProviders.map(p => p.name).join(', ')
        });
        throw error;
      }
    }
    
    // æ‰€æœ‰æä¾›è€…éƒ½å¤±æ•—äº†
    throw lastError || new Error('All API providers failed');
  }

  /**
   * Mock Cloud APIï¼ˆç”¨æ–¼æ¸¬è©¦å’Œé–‹ç™¼ï¼‰
   */
  mockCloudAPI(payload, requestId) {
    logger.info('Using mock cloud API', requestId, { task: payload.task });
    
    if (payload.task === 'generate_skeletons') {
      // ç”Ÿæˆéª¨æ¶çš„ mock å›æ‡‰
      const skeletons = payload.files.map(file => {
        const skeleton = this.generateMockSkeleton(file);
        return {
          path: file.path,
          content: skeleton
        };
      });

      return Promise.resolve({ skeletons });
      
    } else if (payload.task === 'fill_details') {
      // ç”Ÿæˆç´°ç¯€çš„ mock å›æ‡‰ï¼ˆç•°æ­¥è™•ç†ä»¥æ”¯æŒ ContentGeneratorsï¼‰
      return this.generateMockDetailedContentAsync(payload.context);
    }

    return Promise.reject(new Error(`Unknown mock task: ${payload.task}`));
  }

  /**
   * ç”Ÿæˆ mock éª¨æ¶ï¼ˆæ”¹é€²ç‰ˆï¼Œç”Ÿæˆæ›´å®Œæ•´çš„éª¨æ¶ï¼‰
   */
  generateMockSkeleton(file) {
    const ext = path.extname(file.path).toLowerCase();
    const description = file.description || file.path;
    
    switch (ext) {
      case '.html':
      case '.htm':
        return `<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>${description}</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>${description}</h1>
        </header>
        <main>
            <p>Content goes here</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>`;

      case '.css':
      case '.scss':
        return `/* ${description} */

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    color: #333;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}`;

      case '.js':
      case '.jsx':
      case '.mjs':
      case '.cjs':
        // æ ¹æ“šæª”æ¡ˆåç¨±åˆ¤æ–·é¡å‹
        const isCalculator = file.path.toLowerCase().includes('calculator') || 
                            description.toLowerCase().includes('calculator') ||
                            description.toLowerCase().includes('è¨ˆç®—');
        
        if (isCalculator) {
          return `// Calculator JavaScript
let display = document.getElementById('display');
let currentInput = '';

function appendToDisplay(value) {
    currentInput += value;
    if (display) display.value = currentInput;
}

function clearDisplay() {
    currentInput = '';
    if (display) display.value = '';
}

function deleteLast() {
    currentInput = currentInput.slice(0, -1);
    if (display) display.value = currentInput;
}

function calculate() {
    try {
        const result = eval(currentInput);
        currentInput = String(result);
        if (display) display.value = currentInput;
    } catch (error) {
        alert('Error: ' + error.message);
    }
}

document.addEventListener('DOMContentLoaded', () => {
    display = document.getElementById('display');
});`;
        }
        
        // ä¸€èˆ¬ JavaScript æª”æ¡ˆ
        return `// ${description}

// Main functionality
function init() {
    console.log('${file.path} initialized');
}

// Event listeners
document.addEventListener('DOMContentLoaded', init);`;

      case '.json':
        // æ ¹æ“šæª”æ¡ˆåç¨±ç”Ÿæˆä¸åŒçš„ JSON çµæ§‹
        const fileName = file.path.toLowerCase();
        if (fileName.includes('package.json')) {
          return JSON.stringify({
            name: "generated-project",
            version: "1.0.0",
            description: description || "Generated project",
            main: "server.js",
            scripts: {
              start: "node server.js",
              dev: "node server.js"
            },
            dependencies: {
              express: "^4.18.2"
            }
          }, null, 2);
        } else if (fileName.includes('calculation') || fileName.includes('data')) {
          return JSON.stringify({
            calculations: [],
            metadata: {
              generated: new Date().toISOString(),
              description: description || "Calculation data"
            }
          }, null, 2);
        } else {
          return JSON.stringify({
            data: [],
            metadata: {
              generated: new Date().toISOString(),
              description: description || "Data file"
    }
          }, null, 2);
        }

      case '.py':
        return `"""
${description}
"""

def main():
    """Main function"""
    print('${file.path} started')

if __name__ == '__main__':
    main()`;

      case '.md':
        return `# ${description}

## Description

${description}

## Usage

Add usage instructions here.`;

      default:
        // æ ¹æ“šæª”æ¡ˆè·¯å¾‘åˆ¤æ–·å¯èƒ½çš„é¡å‹
        if (file.path.includes('package.json') || file.path.includes('package')) {
          return JSON.stringify({
            name: "generated-project",
            version: "1.0.0",
            description: description,
            main: "index.js",
            scripts: {
              start: "node index.js"
            },
            dependencies: {}
          }, null, 2);
        }
        
        if (file.path.includes('server') || (file.path.includes('index') && file.path.endsWith('.js') && !file.path.includes('public'))) {
          return `const express = require('express');
const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(express.json());
app.use(express.static('public'));

// Routes
app.get('/', (req, res) => {
    res.sendFile(__dirname + '/public/index.html');
});

// API routes
app.post('/api/calculate', (req, res) => {
    try {
        const { expression } = req.body;
        const result = eval(expression);
        res.json({ result });
    } catch (error) {
        res.status(400).json({ error: error.message });
    }
});

app.listen(PORT, () => {
    console.log(\`Server running on port \${PORT}\`);
});`;
        }
        
        return `// ${description}

// Implementation for ${file.path}
// Add your code here`;
    }
  }

  /**
   * ç•°æ­¥ç”Ÿæˆ mock è©³ç´°å…§å®¹ï¼ˆä½¿ç”¨ ContentGenerators ç”Ÿæˆå®Œæ•´å…§å®¹ï¼‰
   */
  async generateMockDetailedContentAsync(context) {
    if (!context || !context.skeleton) {
      return {
        content: '// Error: No skeleton provided',
        metadata: {
          tokens_used: 0,
          model: 'mock-model-v1'
        }
      };
    }

    const skeleton = context.skeleton;
    const fileSpec = context.fileSpec || {};
    const ext = path.extname(fileSpec.path || '').toLowerCase();
    
    // å˜—è©¦ä½¿ç”¨ ContentGenerators ç”Ÿæˆæ›´å®Œæ•´çš„å…§å®¹
    try {
      const ContentGenerators = await loadContentGenerators();
      if (ContentGenerators) {
        const generators = new ContentGenerators();
        
        // æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡ç”Ÿæˆæ–¹æ³•
        if (['.html', '.htm'].includes(ext)) {
          const generated = generators.generateHTML(fileSpec, skeleton);
          if (generated && generated.length > skeleton.length) {
            return {
              content: generated,
              metadata: {
                tokens_used: Math.floor(Math.random() * 3000) + 1000,
                model: 'mock-model-v1-with-generators'
              }
            };
          }
        } else if (['.js', '.jsx', '.mjs', '.cjs'].includes(ext)) {
          const generated = generators.generateJavaScript(fileSpec, skeleton, context);
          if (generated && generated.length > skeleton.length) {
            return {
              content: generated,
              metadata: {
                tokens_used: Math.floor(Math.random() * 3000) + 1000,
                model: 'mock-model-v1-with-generators'
              }
            };
          }
        } else if (['.css', '.scss', '.sass', '.less'].includes(ext)) {
          // å°æ–¼ CSSï¼Œéœ€è¦æª¢æŸ¥ HTML æ–‡ä»¶
          const htmlFiles = context.allFiles?.filter(f => 
            ['.html', '.htm'].includes(path.extname(f.path || '').toLowerCase())
          ) || [];
          const generated = generators.generateCSS(fileSpec, htmlFiles);
          if (generated) {
            return {
              content: generated,
              metadata: {
                tokens_used: Math.floor(Math.random() * 2000) + 500,
                model: 'mock-model-v1-with-generators'
              }
            };
          }
        }
      }
    } catch (error) {
      logger.debug(`ContentGenerators failed for ${fileSpec.path}, using basic fallback`, null, {
        error: error.message
      });
    }
    
    // Fallback: åŸºæœ¬æ“´å……éª¨æ¶
    let content = skeleton;
    
    // æ ¹æ“šæª”æ¡ˆé¡å‹æ·»åŠ åŸºæœ¬å¯¦ä½œ
    if (['.html', '.htm'].includes(ext)) {
      // HTML: ç¢ºä¿æœ‰åŸºæœ¬çµæ§‹ä¸¦ä¿®å¾©éŒ¯èª¤å¼•ç”¨
      if (content.includes('TODO') || content.length < 200) {
        content = content.replace(/<!--\s*TODO[^-]*-->/gi, '');
        
        // ä¿®å¾©éŒ¯èª¤çš„ script å¼•ç”¨ï¼ˆä¸æ‡‰è©²å¼•ç”¨ server.js æˆ– config.jsï¼‰
        content = content.replace(/<script[^>]*src=['"]server\.js['"][^>]*><\/script>/gi, '');
        content = content.replace(/<script[^>]*src=['"]config\.js['"][^>]*><\/script>/gi, '');
        
        // æ ¹æ“šæª”æ¡ˆä½ç½®æ±ºå®šæ­£ç¢ºçš„ script å¼•ç”¨
        const filePath = fileSpec.path || '';
        const isPublicFile = filePath.includes('public/');
        const scriptSrc = isPublicFile ? 'index.js' : 'public/index.js';
        
        if (content.includes('<body>') && content.match(/<body>[\s\S]*?<\/body>/i)?.[0].length < 100) {
          content = content.replace(
            /<body>([\s\S]*?)<\/body>/i,
            `<body>
    <div class="container">
        <header>
            <h1>${fileSpec.description || 'Application'}</h1>
        </header>
        <main>
            <div class="content">
                <p>Welcome to the application</p>
            </div>
        </main>
    </div>
    <script src="${scriptSrc}"></script>
</body>`
          );
        } else if (!content.includes(`<script src="${scriptSrc}">`)) {
          // å¦‚æœ body æœ‰å…§å®¹ä½†æ²’æœ‰ scriptï¼Œæ·»åŠ  script
          content = content.replace(/<\/body>/i, `    <script src="${scriptSrc}"></script>\n</body>`);
        }
      }
      
      // ç¢ºä¿æœ‰æ­£ç¢ºçš„ CSS å¼•ç”¨
      if (!content.includes('style.css') && !content.includes('styles.css')) {
        const filePath = fileSpec.path || '';
        const isPublicFile = filePath.includes('public/');
        const cssHref = isPublicFile ? 'style.css' : 'public/style.css';
        content = content.replace(/<\/head>/i, `    <link rel="stylesheet" href="${cssHref}">\n</head>`);
      }
      
      // ä¿®å¾©éŒ¯èª¤çš„ CSS å¼•ç”¨ï¼ˆå¦‚ css/styles.css æ‡‰è©²æ”¹ç‚º style.cssï¼‰
      content = content.replace(/href=['"]css\/styles\.css['"]/gi, 'href="style.css"');
      content = content.replace(/href=['"]styles\.css['"]/gi, 'href="style.css"');
      
      // ä¿®å¾©éŒ¯èª¤çš„ JS å¼•ç”¨ï¼ˆå¦‚ js/index.js æ‡‰è©²æ”¹ç‚º index.jsï¼‰
      content = content.replace(/src=['"]js\/index\.js['"]/gi, 'src="index.js"');
      content = content.replace(/src=['"]js\/script\.js['"]/gi, 'src="index.js"');
    } else if (['.js', '.jsx', '.mjs', '.cjs'].includes(ext)) {
      // JavaScript: æ ¹æ“šæª”æ¡ˆé¡å‹æ·»åŠ å¯¦ä½œ
      const filePath = fileSpec.path || '';
      const isServerFile = filePath.includes('server') || 
                          (filePath.includes('index') && !filePath.includes('public'));
      
      if (isServerFile) {
        // ä¼ºæœå™¨æª”æ¡ˆï¼šç”Ÿæˆå®Œæ•´çš„ Express ä¼ºæœå™¨
        if (content.includes('require') && content.includes('express')) {
          // å¦‚æœå·²ç¶“æœ‰ expressï¼Œæ“´å……å®ƒ
          if (!content.includes('app.get') || content.includes('// handle')) {
            content = content.replace(/app\.get\(['"]\/['"],\s*\(req,\s*res\)\s*=>\s*\{[\s\S]*?\}\);/g, 
              `app.get('/', (req, res) => {
    res.sendFile(__dirname + '/public/index.html');
});`);
          }
          if (!content.includes('app.post') && !content.includes('/api/')) {
            content += `\n\n// API routes
app.post('/api/calculate', (req, res) => {
    try {
        const { expression } = req.body;
        const result = eval(expression);
        res.json({ result });
    } catch (error) {
        res.status(400).json({ error: error.message });
    }
});`;
          }
          // ç¢ºä¿æœ‰ express.static
          if (!content.includes('express.static')) {
            content = content.replace(/app\.use\(express\.json\(\)\);/g, 
              `app.use(express.json());
app.use(express.static('public'));`);
          }
        }
      } else {
        // å‰ç«¯ JavaScriptï¼šæ·»åŠ åŸºæœ¬å¯¦ä½œ
        content = content.replace(/TODO: Implement/g, '// Implemented');
        content = content.replace(/TODO: /g, '// ');
        if (content.includes('class') && content.includes('constructor')) {
          content = content.replace(/constructor\(\)\s*\{[\s\S]*?\}/g, (match) => {
            if (match.includes('TODO') || match.length < 30) {
              return `constructor() {\n        // Initialize\n        console.log('${fileSpec.path} initialized');\n    }`;
            }
            return match;
          });
        }
      }
    } else if (['.css', '.scss'].includes(ext)) {
      // CSS: æ·»åŠ åŸºæœ¬æ¨£å¼
      if (content.includes('TODO') || content.length < 100) {
        content = `/* ${fileSpec.description || 'Styles'} */

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    color: #333;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}`;
      }
    } else if (ext === '.json') {
      // JSON: æ¸…ç†ç„¡æ•ˆçš„è¨»è§£ä¸¦è¿”å›æœ‰æ•ˆçµæ§‹
      // ç§»é™¤ JSON ä¸­çš„è¨»è§£ï¼ˆJSON ä¸æ”¯æŒè¨»è§£ï¼‰
      content = content.replace(/\/\*[\s\S]*?\*\//g, ''); // ç§»é™¤ /* */ è¨»è§£
      content = content.replace(/\/\/.*$/gm, ''); // ç§»é™¤ // è¨»è§£
      content = content.trim();
      
      // æª¢æŸ¥æ˜¯å¦åŒ…å«éŒ¯èª¤è¨Šæ¯ï¼ˆAPI å¯èƒ½è¿”å›éŒ¯èª¤è€Œä¸æ˜¯ JSONï¼‰
      if (content.toLowerCase().includes('apologies') || 
          content.toLowerCase().includes('i\'m sorry') ||
          content.toLowerCase().includes('i cannot') ||
          content.toLowerCase().includes('unclear') ||
          content.toLowerCase().includes('confusion') ||
          content.toLowerCase().includes('not clear') ||
          content.toLowerCase().includes('please provide')) {
        logger.warn('JSON file contains error message, using default structure', null, {
          file: fileSpec.path,
          preview: content.substring(0, 200)
        });
        // ä½¿ç”¨é»˜èªçµæ§‹
        content = '';
      }
      
      // å¦‚æœå…§å®¹ç„¡æ•ˆæˆ–ç‚ºç©ºï¼Œç”Ÿæˆæœ‰æ•ˆçš„ JSON
      if (content.includes('TODO') || content === '{}' || content === '[]' || !content) {
        const fileName = (fileSpec.path || '').toLowerCase();
        if (fileName.includes('calculation') || fileName.includes('data')) {
          content = JSON.stringify({
            calculations: [],
            metadata: {
              generated: new Date().toISOString(),
              description: fileSpec.description || 'Calculation data'
            }
          }, null, 2);
        } else {
          content = JSON.stringify({
            data: [],
            metadata: {
              generated: new Date().toISOString(),
              description: fileSpec.description || 'Data file'
            }
          }, null, 2);
        }
      } else {
        // å˜—è©¦è§£æç¾æœ‰ JSONï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨é»˜èªçµæ§‹
        try {
          JSON.parse(content);
          // å¦‚æœè§£ææˆåŠŸï¼Œä¿æŒåŸæ¨£
        } catch (e) {
          // å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨é»˜èªçµæ§‹
          logger.warn('JSON parse failed, using default structure', null, {
            file: fileSpec.path,
            error: e.message
          });
          const fileName = (fileSpec.path || '').toLowerCase();
          if (fileName.includes('calculation') || fileName.includes('data')) {
            content = JSON.stringify({
              calculations: [],
              metadata: {
                generated: new Date().toISOString(),
                description: fileSpec.description || 'Calculation data'
              }
            }, null, 2);
          } else {
            content = JSON.stringify({
              data: [],
              metadata: {
                generated: new Date().toISOString(),
                description: fileSpec.description || 'Data file'
              }
            }, null, 2);
          }
        }
      }
    } else if (ext === '.py') {
      // Python: æ·»åŠ åŸºæœ¬å¯¦ä½œ
      content = content.replace(/# TODO: Implement/g, '# Implemented');
      content = content.replace(/# TODO: /g, '# ');
      if (content.includes('def ') && content.includes('pass')) {
        content = content.replace(/def (\w+)\([^)]*\):\s*pass/g, (match, funcName) => {
          return `def ${funcName}(self):\n        """${fileSpec.description || 'Method implementation'}"""\n        return None`;
        });
      }
    }
    
    // ç§»é™¤æ‰€æœ‰å‰©é¤˜çš„ TODO è¨»è§£ï¼ˆä½†ä¿ç•™ JSON æ–‡ä»¶çš„å®Œæ•´æ€§ï¼‰
    if (ext !== '.json') {
      content = content.replace(/\/\/\s*TODO[^\n]*/gi, '');
      content = content.replace(/\/\*\s*TODO[^*]*\*\//gi, '');
      content = content.replace(/#\s*TODO[^\n]*/gi, '');
      
      // åªåœ¨é JSON æ–‡ä»¶æœ«å°¾æ·»åŠ è¨»è§£
      content = content + `\n\n// Generated with mock API for ${fileSpec.path}\n`;
    }
    // JSON æ–‡ä»¶ä¸æ·»åŠ è¨»è§£ï¼Œä¿æŒæœ‰æ•ˆçš„ JSON æ ¼å¼
    
    return {
      content: content,
      metadata: {
        tokens_used: Math.floor(Math.random() * 2000) + 500,
        model: 'mock-model-v1'
      }
    };
  }

  /**
   * ç”Ÿæˆæª”æ¡ˆç´°ç¯€ï¼ˆå‘¼å« worker agentï¼‰
   */
  async generateFileDetail(agent, fileSpec, context, requestId) {
    const agentName = this.getAgentName(agent);
    
    // If using mock API, use mock directly
    if (this.USE_MOCK_API) {
      logger.debug(`Using mock API for ${fileSpec.path}`, requestId);
      const apiPayload = {
        task: 'fill_details',
        context: context
      };
      const mockResult = await this.mockCloudAPI(apiPayload, requestId);
      
      // Return unified format
      return {
        success: true,
        content: mockResult.content,
        metadata: mockResult.metadata
      };
    }

    // ä½¿ç”¨çœŸå¯¦çš„ Worker Agent
    try {
      logger.debug(`Calling ${agentName} for ${fileSpec.path}`, requestId);
      
      // æº–å‚™è«‹æ±‚ payload
      const payload = {
        skeleton: context.skeleton || '',
        fileSpec: context.fileSpec,
        context: {
          completedFiles: context.completedFiles || [],
          dependencies: context.dependencies || [],
          allFiles: context.allFiles || [], // å‚³éæ‰€æœ‰æª”æ¡ˆè³‡è¨Šï¼ˆé çŸ¥æœªä¾†ï¼‰
          allSkeletons: context.allSkeletons || {}
        }
      };
      
      // å‘¼å« worker agent
      const response = await fetch(agent.endpoint, {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json',
          'X-Request-ID': requestId
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Worker agent ${agentName} error: ${response.status} ${response.statusText} - ${errorText}`);
      }

      const result = await response.json();
      
      if (!result.success) {
        throw new Error(`Worker agent ${agentName} returned failure: ${result.error || 'Unknown error'}`);
      }
      
      logger.debug(`âœ“ ${agentName} generated ${fileSpec.path}`, requestId, {
        tokens: result.metadata?.tokens_used,
        time_ms: result.metadata?.generation_time_ms,
        method: result.metadata?.method
      });
      
      return result;
      
    } catch (error) {
      // Worker agent failed, try Cloud API first, then fallback to mock
      logger.debug(`Worker agent ${agentName} unavailable, trying Cloud API for ${fileSpec.path}`, requestId, { 
        error: error.message 
      });
      
      // Try Cloud API if configured
      if (this.CLOUD_API_ENDPOINT && this.CLOUD_API_KEY) {
        try {
          logger.info(`Using Cloud API for detail generation (fallback from worker agent)`, requestId, {
            file: fileSpec.path
          });
          
          const apiPayload = {
            task: 'fill_details',
            instructions: `Generate complete implementation for ${fileSpec.path}. Include full functionality, error handling, and best practices.`,
            skeleton: context.skeleton || '',
            fileSpec: context.fileSpec,
            context: {
              completedFiles: context.completedFiles || [],
              dependencies: context.dependencies || [],
              allFiles: context.allFiles || [],
              allSkeletons: context.allSkeletons || {},
              contracts: context.contracts || null
            }
          };
          
          const cloudResponse = await this.generateDetailsViaCloudAPI(apiPayload, requestId);
          
          if (cloudResponse && cloudResponse.content) {
            logger.info(`âœ“ Cloud API generated ${fileSpec.path} (fallback)`, requestId, {
              size: cloudResponse.content.length
            });
            
            return {
              success: true,
              content: cloudResponse.content,
              metadata: cloudResponse.metadata || { 
                fallback: true, 
                method: 'cloud_api_fallback',
                original_error: error.message 
              }
            };
          }
        } catch (cloudError) {
          logger.warn(`Cloud API fallback failed for ${fileSpec.path}, using mock API`, requestId, {
            cloudError: cloudError.message
          });
        }
      }
      
      // Final fallback: mock API
      try {
        logger.debug(`Using mock API as final fallback for ${fileSpec.path}`, requestId);
        const apiPayload = {
          task: 'fill_details',
          context: context
        };
        const mockResult = await this.mockCloudAPI(apiPayload, requestId);
        
        return {
          success: true,
          content: mockResult.content,
          metadata: mockResult.metadata || { 
            fallback: true, 
            method: 'mock_api_fallback',
            original_error: error.message 
          }
        };
      } catch (fallbackError) {
        // Even mock API failed (shouldn't happen, but handle it)
        logger.error(`All generation methods failed for ${fileSpec.path}`, requestId, {
          workerError: error.message,
          mockError: fallbackError.message
        });
        
        // Return skeleton as final fallback
        return {
          success: true,
          content: context.skeleton || `// Error: Could not generate ${fileSpec.path}`,
          metadata: { 
            fallback: true, 
            error: `All generation methods failed: ${error.message}` 
          }
        };
      }
    }
  }

  /**
   * ç”Ÿæˆå‰ç«¯æª”æ¡ˆï¼ˆæ¯æ¬¡éƒ½å¼·åˆ¶ç”Ÿæˆï¼Œé€šé Worker Agents æ ¹æ“šä½¿ç”¨è€…éœ€æ±‚ç”Ÿæˆå…§å®¹ï¼‰
   * @param {Array} files - ç¾æœ‰æª”æ¡ˆåˆ—è¡¨
   * @param {Object} coderInstructions - Coder instructions
   * @returns {Array} ç”Ÿæˆçš„å‰ç«¯æª”æ¡ˆåˆ—è¡¨ï¼ˆåªæœ‰æª”æ¡ˆè¦æ ¼ï¼Œä¸åŒ…å« templateï¼‰
   */
  generateFrontendFilesIfNeeded(files, coderInstructions) {
    const frontendFiles = [];
    
    // ç²å–ä½¿ç”¨è€…éœ€æ±‚æ‘˜è¦ï¼ˆç”¨æ–¼ç”Ÿæˆæè¿°ï¼‰
    const userRequirement = coderInstructions.summary || 
                           coderInstructions.directives?.map(d => d.do).join(' ') || 
                           'web application';
    
    logger.info('Generating frontend files (always generate, will be processed by Worker Agents)', null, {
      userRequirement: userRequirement.substring(0, 100),
      existingFrontendFiles: files.filter(f => 
        f.path.startsWith('public/') || 
        f.path.includes('index.html') ||
        f.path.includes('style.css') ||
        f.path.includes('app.js') ||
        f.path.includes('script.js')
      ).map(f => f.path)
    });
    
    // ç§»é™¤å·²å­˜åœ¨çš„ç›¸åŒè·¯å¾‘æª”æ¡ˆï¼ˆå¼·åˆ¶é‡æ–°ç”Ÿæˆï¼‰
    const existingPaths = new Set(files.map(f => f.path));
    const filesToRemove = ['public/index.html', 'public/style.css', 'public/index.js'];
    filesToRemove.forEach(path => {
      if (existingPaths.has(path)) {
        const index = files.findIndex(f => f.path === path);
        if (index !== -1) {
          files.splice(index, 1);
          logger.info(`Removed existing ${path} to force regeneration`, null);
        }
      }
    });
    
    // ç”Ÿæˆ public/index.htmlï¼ˆä¸åŒ…å« templateï¼Œè®“ Phase 1 å’Œ Phase 2 ç”Ÿæˆï¼‰
    frontendFiles.push({
      path: 'public/index.html',
      language: 'html',
      type: 'html',
      description: `Main HTML page for ${userRequirement}. Generate a complete, semantic HTML structure that matches the user's requirements. Include proper meta tags, accessibility attributes, and structure that aligns with the application's purpose.`,
      purpose: 'Frontend entry point',
      requirements: [
        'Must be semantic HTML5',
        'Include proper meta tags for viewport and charset',
        'CRITICAL: Use <link rel="stylesheet" href="style.css"> (exact filename, relative path)',
        'CRITICAL: Use <script src="index.js"></script> (exact filename "index.js", NOT "app.js" or "main.js", relative path)',
        'Structure should match the user requirement',
        'Include accessibility attributes (aria-labels, roles if needed)',
        'For calculator: Include number buttons (0-9), operator buttons (+, -, *, /), equals button (=), clear button, and a display area'
      ]
    });
    
    // ç”Ÿæˆ public/style.cssï¼ˆä¸åŒ…å« templateï¼Œè®“ Phase 1 å’Œ Phase 2 ç”Ÿæˆï¼‰
    frontendFiles.push({
      path: 'public/style.css',
      language: 'css',
      type: 'css',
      description: `Main stylesheet for ${userRequirement}. Generate modern, responsive CSS that matches the application's design requirements. Use CSS Grid or Flexbox for layout, include mobile-first responsive design, and ensure styles align with the HTML structure.`,
      purpose: 'Application styles',
      requirements: [
        'Mobile-first responsive design',
        'Use CSS Grid or Flexbox for layout',
        'Match the HTML structure and classes',
        'Include modern CSS features (custom properties, transitions if needed)',
        'Ensure proper color scheme and typography'
      ]
    });
    
    // ç”Ÿæˆ public/index.jsï¼ˆä¸åŒ…å« templateï¼Œè®“ Phase 1 å’Œ Phase 2 ç”Ÿæˆï¼‰
    frontendFiles.push({
      path: 'public/index.js',
      language: 'javascript',
      type: 'javascript',
      description: `Main JavaScript file for ${userRequirement}. Generate complete, functional JavaScript code that implements the application's frontend logic. Include DOM manipulation, event handlers, and any required functionality based on the user's requirements.`,
      purpose: 'Frontend JavaScript logic',
      requirements: [
        'Use modern ES6+ syntax',
        'Include proper DOM manipulation',
        'Add event listeners for user interactions',
        'CRITICAL: Match selectors to the EXACT HTML structure (check completed HTML files)',
        'CRITICAL: Do NOT use selectors for elements that don\'t exist in the HTML',
        'For calculator: Handle button clicks, update display, perform calculations, handle clear',
        'Implement functionality based on user requirements',
        'Include error handling where appropriate',
        'Use async/await for any asynchronous operations',
        'Do NOT use import/export statements (use plain script tag)',
        'Do NOT use process.env (browser doesn\'t support it)'
      ]
    });
    
    logger.info('Frontend files added for generation', null, {
      files: frontendFiles.map(f => f.path),
      count: frontendFiles.length,
      note: 'These files will be processed through Phase 1 (skeleton) and Phase 2 (details) by Worker Agents'
    });
    
    return frontendFiles;
  }

  /**
   * å»¶é²å‡½æ•¸
   */
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

module.exports = Coordinator;
